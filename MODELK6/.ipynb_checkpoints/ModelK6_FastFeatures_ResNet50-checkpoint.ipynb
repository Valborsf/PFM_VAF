{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ur34g7Fbi5lr"
   },
   "source": [
    "# Notebook- Fast Feature Extraction  -Model K6_0- ResNet50\n",
    "# Author : V.Albors   Date : 07.02.2020\n",
    "# Purpose : Fast Feature Extraction without Data augmentation ( on VGG16 and ResNet50 ) \n",
    "\n",
    "\n",
    "**Input** :  \n",
    "  * CSV files that identify the images to use as train and validation. CSV files are in directory csv_dir   \n",
    "  * Images from train and validation. Images are in directory : imag_dir  \n",
    "  * Saved model. Model is in directory : model_bin_dir  \n",
    "  \n",
    "**Output**:  \n",
    "  * Download of the model trained with train dataset\n",
    "  * Download the history of the model in order to be evaluated \n",
    "\n",
    "**Process**:  \n",
    "  * Import VGG16 or ResNet50\n",
    "  * Configure the convolutional base  ( use weights from imagenet, no use the dense classifier on top, shape of tensors feed ) \n",
    "  *  Print Network, save network\n",
    "  *  Dataframes are created for Training and Validation\n",
    "  *  Extract features from the data and labels using the  conv.base.predict  operation. \n",
    "  *  Flatten the extracted features knowing the dimensions of the last layer of the VGG16 or ResNet50 . \n",
    "  *  Build a densely connected classifier \n",
    "  *  Compile network\n",
    "  *  Train the model  using the flatten extracted features using model.fit \n",
    "  *  With Callbacks \n",
    "  *  The model is Saved\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU') \n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "10.0\n",
      "7.6\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow version \n",
    "print(tf.__version__)\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "print(tf_build_info.cuda_version_number)\n",
    "# Cuda Version 9.0 in v1.10.0\n",
    "print(tf_build_info.cudnn_version_number)\n",
    "# CudNN 7 in v1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the model, directories & if to train the model \n",
    "#Pre_model = \"ResNet50\"\n",
    "Pre_model = \"ResNet50\"\n",
    "Model_directory = \"MODELK6\"\n",
    "if Pre_model == \"ResNet50\":\n",
    "    Model_name = \"Model6_0_ResNet50\"\n",
    "else:\n",
    "    Model_name = \"Model6_0_VGG16\"\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confusion_ROC_AUC', 'create_column_tensor', 'create_label_tensor', 'create_val_test', 'define_dirs', 'extract_images_bm', 'extract_images_train', 'load_hist_model', 'load_images', 'load_images_tf', 'model_load', 'plot_save_acc_loss', 'print_network', 'process_clinical_info', 'read_dataframes', 'read_dataframes_tables', 'reproducible_results', 'save_model', 'save_network_json', 'start', 'stop', 'to_one_hot', 'to_one_hot_words', 'xi_squared']\n"
     ]
    }
   ],
   "source": [
    "# Import routines\n",
    "import sys  \n",
    "subrc_dir = \"/home/valborsf/Documents/UOC/PFMProject/\"\n",
    "\n",
    "\n",
    "sys.path.append(subrc_dir)  \n",
    "from  Models_routines import *\n",
    "import inspect\n",
    "\n",
    "# List functions inside the module\n",
    "import Models_routines as module\n",
    "functions = inspect.getmembers(module, inspect.isfunction)\n",
    "lsfunctions = [item[0] for item in functions]\n",
    "print ( lsfunctions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible results \n",
    "reproducible_results ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define directories\n",
    "(root_dir,json_dir,imag_dir,csv_dir,model_json_dir,model_bin_dir,results_dir,Tensor_dir) = define_dirs(Model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset without SONIC disturbing images\n",
    "json_dir =  root_dir +\"/DataNew/ALL_JSON/\"                # .json dir images\n",
    "imag_dir =  root_dir +\"/DataNew/ALL_IMAGES/\"              # .png dir - images\n",
    "\n",
    "# directories for  CSV's\n",
    "csv_dir =  root_dir +\"/DataNew4/CSV/\"                      # .csv dir - dftrain, dfval, dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "if Pre_model == \"ResNet50\":\n",
    "    from keras.applications import ResNet50\n",
    "elif Pre_model == \"VGG16\":\n",
    "    from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valborsf/anaconda3/envs/gpu2/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56442880/94653016 [================>.............] - ETA: 45s"
     ]
    }
   ],
   "source": [
    "if Pre_model == \"ResNet50\":\n",
    "       conv_base = ResNet50 ( weights='imagenet',  # Weight checkpoint from which to initialize the model \n",
    "                     include_top = False,        # No include the dense connected classifier on top\n",
    "                     input_shape = (150,150,3))  # Shape of the image tensors to feed in the network\n",
    "\n",
    "elif Pre_model == \"VGG16\":\n",
    "       conv_base = VGG16  ( weights='imagenet',    # Weight checkpoint from which to initialize the model \n",
    "                     include_top = False,        # No include the dense connected classifier on top\n",
    "                     input_shape = (150,150,3))  # Shape of the image tensors to feed in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Network \n",
    "#print_network (results_dir, conv_base, Model_name)\n",
    "#Save Network \n",
    "save_network_json (model_json_dir, conv_base, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train,validation & Test \n",
    "(dftrain, dfval, dftest) = read_dataframes(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is time consuming !\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "def extract_features( dataframe, sample_count, Pre_model, test_dataframe):\n",
    "    if Pre_model == \"VGG16\":\n",
    "           features = np.zeros(shape=(sample_count,4,4,512))  #Last layer VGG16\n",
    "    elif Pre_model == \"ResNet50\":\n",
    "           features = np.zeros(shape=(sample_count,5,5,2048))  #Last layer ResNet50\n",
    "    labels = np.zeros (shape=(sample_count))\n",
    "    \n",
    "    if test_dataframe == \"N\":\n",
    "        generator = datagen.flow_from_dataframe(\n",
    "           dataframe=dataframe,       # Data frame with info of the files and targets\n",
    "           directory=imag_dir,        # path to the directory to read the images from\n",
    "           x_col='file_name_ext',     # column in the data frame that contains the file names \n",
    "           y_col='bm',                # column in the data frame that has the target data\n",
    "           target_size=(150, 150),    # dimensions that the images will be resized\n",
    "           batch_size=batch_size,     # size of the batches of data (default: 32).\n",
    "           class_mode='binary')       # Mode for yielding the targets:1D numpy array of binary labels\n",
    "        \n",
    "    elif test_dataframe == \"Y\":\n",
    "        generator = datagen.flow_from_dataframe(\n",
    "            dataframe=dataframe,       # Data frame with info of the files and targets\n",
    "            directory=imag_dir,        # path to the directory to read the images from\n",
    "            x_col='file_name_ext',     # column in the data frame that contains the file names \n",
    "            y_col='bm',                # column in the data frame that has the target data\n",
    "            target_size=(150, 150),    # dimensions that the images will be resized\n",
    "            batch_size=batch_size,             # size of the batches of data (default: 32).\n",
    "            shuffle=False,             # IMPORTANT !!! Do not shuffle test data !!!!!!!!!!!!!\n",
    "            class_mode='binary')       # Mode for yielding the targets:1D numpy array of binary labels\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size :(i+1)* batch_size] = features_batch\n",
    "        labels [i*batch_size : (i+1) * batch_size]= labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels \n",
    "\n",
    "num_train = 2100\n",
    "num_val = 700\n",
    "num_test = 700\n",
    "\n",
    "train_features, train_labels = extract_features(dftrain,  num_train, Pre_model, \"N\")\n",
    "validation_features, validation_labels = extract_features ( dfval, num_val, Pre_model, \"N\")\n",
    "test_features, test_labels = extract_features(dftest, num_test, Pre_model, \"Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tensors \n",
    "print ( Pre_model)\n",
    "print (type (train_features) )\n",
    "print (type (train_labels) )\n",
    "print (train_features.shape) \n",
    "print (train_labels.shape) \n",
    "#print (train_features[0,0,0])\n",
    "#print (train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Tensors shape for the different PreNets\n",
    "\n",
    "if Pre_model == \"ResNet50\":\n",
    "# ResNet50\n",
    "       train_features = np.reshape ( train_features, (num_train, 5*5*2048))\n",
    "       validation_features = np.reshape ( validation_features, (num_val, 5*5*2048))\n",
    "       test_features = np.reshape ( test_features, (num_test, 5*5*2048))\n",
    "elif Pre_model == \"VGG16\":\n",
    "#VGG16\n",
    "       train_features = np.reshape ( train_features, (num_train, 4*4*512))\n",
    "       validation_features = np.reshape ( validation_features, (num_val, 4*4*512))\n",
    "       test_features = np.reshape ( test_features, (num_test, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Network \n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.regularizers import l2\n",
    "model = models.Sequential ()\n",
    "\n",
    "if Pre_model == \"VGG16\":\n",
    "    model.add(layers.Dense(256, kernel_regularizer=l2(0.0005), activation='relu', input_dim = 4*4*512))    # VGG16\n",
    "\n",
    "elif Pre_model == \"ResNet50\":\n",
    "    model.add(layers.Dense(256, kernel_regularizer=l2(0.0005), activation='relu', input_dim = 5*5*2048))  # ResNet50\n",
    "\n",
    "model.add(layers.Dense(1000, kernel_regularizer=l2(0.0005), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(200, kernel_regularizer=l2(0.0005), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Network \n",
    "from keras import optimizers \n",
    "model.compile ( loss='binary_crossentropy',\n",
    "#               optimizer = optimizers.RMSprop(lr=1e-4),\n",
    "               optimizer = optimizers.Adam(lr=1e-4),\n",
    "               metrics= ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Network \n",
    "Model_name_train = Model_name + \"_train\"\n",
    "#print_network (results_dir, model, Model_name_train)\n",
    "#Save Network \n",
    "save_network_json (model_json_dir, model, Model_name_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbackt to be used \n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callbacks_list = [\n",
    "# No early stopping when augmentation \n",
    "         keras.callbacks.EarlyStopping (\n",
    "             monitor = 'val_loss',        # Monitors the val loss\n",
    "             patience = 10,),              # Interrupt if acc no improve in 10 epochs\n",
    "\n",
    "#  ModelCheckpoint to store the weights of the best performing epoch. \n",
    "    \n",
    "         keras.callbacks.ModelCheckpoint(filepath=model_bin_dir+\"Best_weights\"+Model_name+\".hdf5\", \n",
    "             monitor = 'val_loss', # Won't overwritte the model file unless val_loss has\n",
    "             verbose=1,            # improve \n",
    "             save_best_only=True),\n",
    "         \n",
    "#         keras.callbacks.TensorBoard(\n",
    "#             log_dir =  Tensor_dir, \n",
    "#            histogram_freq = 0,  ) # No histograms - validation data must be provided as a tensor\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Network\n",
    "if TRAIN :\n",
    "    history = model.fit ( train_features, train_labels, \n",
    "                      epochs = 200,\n",
    "                      callbacks=callbacks_list,   \n",
    "                      batch_size = 32, \n",
    "                      validation_data = ( validation_features, validation_labels))\n",
    "    save_model(model, history, model_bin_dir, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Test if not need to Train \n",
    "if not TRAIN :\n",
    "    model = model_load ( model_bin_dir, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display curves of loss and accuracy during training and save results \n",
    "plot_save_acc_loss(results_dir, history.history, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Test if not need to Train \n",
    "\n",
    "if Pre_model == \"ResNet50\":\n",
    "        Model_name = \"Model6_0_ResNet50\"\n",
    "else:\n",
    "        Model_name = \"Model6_0_VGG16\"\n",
    "model = model_load ( model_bin_dir, Model_name)\n",
    "model.load_weights(model_bin_dir+\"Best_weights\"+Model_name+\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate your model  -> Evaluation number -> nº samples/ size batch times\n",
    "#scores = model.evaluate(test_generator, verbose=1, steps = 31)\n",
    "# Evaluates with numpy arrays\n",
    "scores = model.evaluate(test_features, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Res net50  loss = 0.52  acc=0.74\n",
    "# VGG        Loss = 77    Accuracy of 76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "# This takes time !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "y_pred_keras = model.predict(test_features).ravel()        # y_pred probabilities\n",
    "y_pred = y_pred_keras > 0.5                                # y_pred_class : if >0.5  = True => Malignant\n",
    "#y_test = test_generator.classes                            # Ground truth\n",
    "#class_labels = list(test_generator.class_indices.keys())   # Class labels\n",
    "y_test = dftest.bm.astype('category').cat.codes\n",
    "class_labels= dftest.bm.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Metrics + Confusion ROC AUC\n",
    "confusion_ROC_AUC ( y_test, y_pred, y_pred_keras, class_labels, results_dir, Model_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocess_Fit4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "“gpu2”",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
