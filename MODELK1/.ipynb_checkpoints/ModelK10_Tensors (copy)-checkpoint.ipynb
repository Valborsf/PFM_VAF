{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ur34g7Fbi5lr"
   },
   "source": [
    "# Notebook- Model K1 - Tensors   \n",
    "# Author : V.Albors   Date : 22.01.2020\n",
    "# Purpose : Train with tensors\n",
    "\n",
    "\n",
    "\n",
    "**Input** :  \n",
    "  * CSV files that identify the images to use as train and validation. CSV files are in directory csv_dir   \n",
    "  * Images from train and validation. Images are in directory : imag_dir  \n",
    "  * Saved model. Model is in directory : model_bin_dir  \n",
    "  \n",
    "**Output**:  \n",
    "  * Download of the model trained with train dataset - \n",
    "  * Download the history of the model in order to be evaluated \n",
    "\n",
    "**Process**:  \n",
    " * Read Train and Validation images ( identified in the .csv files ) from the imag_dir directory   \n",
    " * Create a train and validation input & label tensors (no augmentation)\n",
    " * Define the architecture of model : \n",
    "                        \n",
    " * Train the model with the train dataset with callbacks (  ModuleCheckPoint , Early Stopping)\n",
    " * Save the trained model and history of the model in directory model_bin_dir \n",
    " * Paint the Accuracy and Loss curves\n",
    " * Create results : Metrics \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU') \n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "10.0\n",
      "7.6\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow version \n",
    "print(tf.__version__)\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "print(tf_build_info.cuda_version_number)\n",
    "# Cuda Version 9.0 in v1.10.0\n",
    "print(tf_build_info.cudnn_version_number)\n",
    "# CudNN 7 in v1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the model \n",
    "Model_directory = \"MODELK1\"\n",
    "Model_name = \"ModelK1_00\"\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confusion_ROC_AUC', 'create_column_tensor', 'create_label_tensor', 'create_val_test', 'define_dirs', 'extract_images_bm', 'extract_images_train', 'load_hist_model', 'load_images', 'load_images_tf', 'model_load', 'plot_save_acc_loss', 'print_network', 'process_clinical_info', 'read_dataframes', 'read_dataframes_tables', 'reproducible_results', 'save_model', 'save_network_json', 'start', 'stop', 'to_one_hot', 'to_one_hot_words', 'xi_squared']\n"
     ]
    }
   ],
   "source": [
    "# Import routines\n",
    "import sys  \n",
    "subrc_dir = \"/home/valborsf/Documents/UOC/PFMProject/\"\n",
    "\n",
    "sys.path.append(subrc_dir)  \n",
    "from  Models_routines import *\n",
    "import inspect\n",
    "\n",
    "# List functions inside the module\n",
    "import Models_routines as module\n",
    "functions = inspect.getmembers(module, inspect.isfunction)\n",
    "lsfunctions = [item[0] for item in functions]\n",
    "print ( lsfunctions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible results \n",
    "reproducible_results ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "(root_dir,json_dir,imag_dir,csv_dir,model_json_dir,model_bin_dir,results_dir,Tensor_dir) = define_dirs(Model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset without SONIC disturbing images\n",
    "json_dir =  root_dir +\"/DataNew/ALL_JSON/\"                # .json dir images\n",
    "imag_dir =  root_dir +\"/DataNew/ALL_IMAGES/\"              # .png dir - images\n",
    "\n",
    "# directories for  CSV's\n",
    "csv_dir =  root_dir +\"/DataNew4/CSV/\"                      # .csv dir - dftrain, dfval, dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/valborsf/Documents/UOC/PFMProject/DataNew4/CSV/\n"
     ]
    }
   ],
   "source": [
    "# Load train,validation & Test \n",
    "(dftrain, dfval, dftest) = read_dataframes(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label tensor\n",
    "train_label_tensor = create_label_tensor(dftrain)\n",
    "val_label_tensor = create_label_tensor(dfval)\n",
    "#test_label_tensor = create_label_tensor(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ReadFile in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DecodeJpeg in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ExpandDims in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ResizeBilinear in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Squeeze in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Create tensors from images\n",
    "# Load Images \n",
    "height_imag = 150 \n",
    "width_imag = 150\n",
    "# This step is very time consuming !!!!!!!\n",
    "train_image_tensor  = load_images_tf(dftrain,height_imag,width_imag)\n",
    "val_image_tensor  = load_images_tf(dfval,height_imag,width_imag)\n",
    "#test_image_tensor  = load_images(dftest,height_imag,width_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Model 1 : Image to Predict Melanoma\n",
    "\n",
    "image_inputs = Input(shape=(height_imag,width_imag,3))\n",
    "m2 = layers.Conv2D(64, (3,3), activation='relu')(image_inputs)\n",
    "m2 = layers.MaxPooling2D((2,2))(m2)\n",
    "m2 = layers.Conv2D(32, (3,3),  activation='relu')(m2)\n",
    "m2 = layers.MaxPooling2D((2,2))(m2)\n",
    "m2 = layers.Conv2D(128, (3,3), activation='relu')(m2)\n",
    "m2 = layers.MaxPooling2D((2,2))(m2)\n",
    "m2 = layers.Flatten()(m2)\n",
    "m2 = layers.Dropout(0.23)(m2)\n",
    "m2 = layers.Dense (512, activation='relu')(m2)\n",
    "\n",
    "benign_malign = layers.Dense (1, activation='sigmoid')(m2)\n",
    "\n",
    "\n",
    "# Model instantiation\n",
    "model = Model(image_inputs, benign_malign)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Network \n",
    "print_network (results_dir, model, Model_name)\n",
    "#Save Network \n",
    "save_network_json (model_json_dir, model, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compile\n",
    "from tensorflow.keras import optimizers\n",
    "model.compile ( loss='binary_crossentropy',\n",
    "#               optimizer = optimizers.RMSprop(lr=1e-4),\n",
    "               optimizer = optimizers.Adam(lr=1e-4),\n",
    "               metrics= ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks_list = [\n",
    "# EarlyStopping when the model does not improve in loss\n",
    "\n",
    "         tf.keras.callbacks.EarlyStopping (\n",
    "             monitor = 'val_loss',             # Monitors the accuracy\n",
    "             verbose=1,                        # log when finishes\n",
    "             patience = 4,),                   # Interrupt if acc no improve in 4 epochs\n",
    "\n",
    "#  ModelCheckpoint to store the weights of the best performing epoch. \n",
    "    \n",
    "         tf.keras.callbacks.ModelCheckpoint(filepath=model_bin_dir+\"Best_weights\"+Model_name+\".hdf5\", \n",
    "             monitor = 'val_loss', # Won't overwritte the model file unless val_loss has\n",
    "             verbose=1,            # improve \n",
    "             save_best_only=True),\n",
    "         \n",
    "#         keras.callbacks.TensorBoard(\n",
    "#             log_dir =  Tensor_dir, \n",
    "#            histogram_freq = 1,\n",
    "#            )\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "epochs= 200\n",
    "batch_size = 64\n",
    "import time\n",
    "start_time = time.time()\n",
    "history = model.fit (train_image_tensor, \n",
    "           train_label_tensor, \n",
    "           epochs = epochs, \n",
    "           batch_size = batch_size, \n",
    "           callbacks=callbacks_list,\n",
    "           validation_data =( val_image_tensor,val_label_tensor))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print( time.strftime('Time spent in training :'\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "save_model(model, history, model_bin_dir, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Test if not need to Train \n",
    "if not TRAIN :\n",
    "    model = model_load ( model_bin_dir, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display curves of loss and accuracy during training and save results \n",
    "plot_save_acc_loss(results_dir, history.history, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model \n",
    "# Load weights \n",
    "\n",
    "#model = build_model()\n",
    "#model.load_weights('my_weights.model')\n",
    "TRAIN = False\n",
    "if not TRAIN :\n",
    "    Model_name = \"ModelK1_00\"\n",
    "    model = model_load ( model_bin_dir, Model_name)\n",
    "    model.load_weights(model_bin_dir+\"Best_weights\"+Model_name+\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors from images\n",
    "# Load Images \n",
    "\n",
    "# This step is very time consuming !!!!!!!\n",
    "test_image_tensor  = load_images_tf(dftest,height_imag,width_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label tensor\n",
    "test_label_tensor = create_label_tensor(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ROC /AUC\n",
    "scores = model.evaluate(test_image_tensor, test_label_tensor, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss 0.50  Acc=0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "# This takes time !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "y_pred_keras = model.predict(test_image_tensor).ravel()   # y_pred_probabilities\n",
    "y_pred = y_pred_keras > 0.5                                # y_pred_class : if >0.5  = True => Malignant\n",
    "y_test = dftest.bm.astype('category').cat.codes            # Ground truth \n",
    "class_labels= dftest.bm.unique()                           # Labels of ground truth \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Metrics + Confusion ROC AUC\n",
    "confusion_ROC_AUC ( y_test, y_pred, y_pred_keras, class_labels, results_dir, Model_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()  # Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocess_Fit4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "“gpu2”",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
