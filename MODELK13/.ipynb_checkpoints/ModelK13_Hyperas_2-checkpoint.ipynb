{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook- Preprocessing & Fit : ModelK13_1  Optimization Hyperas\n",
    "# Author : V.Albors   Date : 21.01.2020\n",
    "# Purpose : Optimization by Hyperas of Batch size, dropout, learning rate\n",
    "\n",
    "\n",
    "**Input** :  \n",
    "  * CSV files that identify the images to use as train and validation. CSV files are in directory csv_dir   \n",
    "  * Images from train and validation. Images are in directory : imag_dir  \n",
    "  \n",
    "  \n",
    "**Output**:  \n",
    " * Optimize parameters :\n",
    "     * One layer + \n",
    "     * Batch size\n",
    "     * Dropout\n",
    "     * Learning rate - optimizer  Adam\n",
    "      \n",
    "\n",
    "**Process**:  \n",
    " * Read Train and Validation images ( identified in the .csv files ) from the imag_dir directory  \n",
    " * Create a model \n",
    " * Compile Network \n",
    " * Train the model to find best hyperparameters\n",
    " \n",
    " \n",
    "**To do hyper-parameter optimization on this model, just wrap the parameters you want to optimize into double curly brackets and choose a distribution over which to run the algorithm**\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "# Do not write is do no want in choice \n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU') \n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the model, directories & if to train the model \n",
    "Model_directory = \"MODELN13\"\n",
    "Model_name = \"ModelK13_1\"\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confusion_ROC_AUC', 'create_column_tensor', 'create_label_tensor', 'create_val_test', 'define_dirs', 'extract_images_bm', 'extract_images_train', 'load_hist_model', 'load_images', 'load_images_tf', 'model_load', 'plot_save_acc_loss', 'print_network', 'process_clinical_info', 'read_dataframes', 'read_dataframes_tables', 'reproducible_results', 'save_model', 'save_network_json', 'start', 'stop', 'to_one_hot', 'to_one_hot_words', 'xi_squared']\n"
     ]
    }
   ],
   "source": [
    "# Import routines\n",
    "import sys  \n",
    "subrc_dir = \"/home/valborsf/Documents/UOC/PFMProject/\"\n",
    "\n",
    "sys.path.append(subrc_dir)  \n",
    "from  Models_routines import *\n",
    "import inspect\n",
    "\n",
    "# List functions inside the module\n",
    "import Models_routines as module\n",
    "functions = inspect.getmembers(module, inspect.isfunction)\n",
    "lsfunctions = [item[0] for item in functions]\n",
    "print ( lsfunctions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "(root_dir,json_dir,imag_dir,csv_dir,model_json_dir,model_bin_dir,results_dir,Tensor_dir) = define_dirs(Model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "        csv_dir =  root_dir +\"/DataNew4/CSV/\"   \n",
    "        (dftrain, dfval, dftest) = read_dataframes(csv_dir)\n",
    "        height_imag = 150 \n",
    "        width_imag = 150\n",
    "        x_train  = load_images_tf(dftrain,height_imag,width_imag)\n",
    "        x_val    = load_images_tf(dfval,height_imag,width_imag)\n",
    "        x_test   = load_images_tf(dftest,height_imag,width_imag)\n",
    "        y_train  = create_label_tensor(dftrain)\n",
    "        y_val    = create_label_tensor(dfval)\n",
    "        y_test   = create_label_tensor(dftest)\n",
    "        return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    import keras\n",
    "    from hyperopt import Trials, STATUS_OK, tpe\n",
    "    from keras import layers\n",
    "    from keras import models\n",
    "    from hyperas import optim\n",
    "    from hyperas.distributions import choice, uniform\n",
    "    import numpy as np\n",
    "    from keras.utils import np_utils\n",
    "    \n",
    "    model = models.Sequential ()\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu', input_shape=(150,150,3)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    " \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout({{uniform(0, 1)}}))      \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "\n",
    "    from keras import optimizers \n",
    "    from keras.optimizers import Adam\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr={{choice([10**-4, 10**-3, 10**-2])}})\n",
    "\n",
    "    optim = adam\n",
    "    \n",
    "    \n",
    "    model.compile ( loss='binary_crossentropy',\n",
    "               optimizer = optim,\n",
    "               metrics= ['acc'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    \n",
    "    epochs = 100\n",
    "    \n",
    "    result = model.fit(x_train, y_train,\n",
    "                      batch_size={{choice([32, 64])}},\n",
    "                      epochs=100,\n",
    "                      verbose=2,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                      callbacks=[early_stopping])\n",
    "\n",
    "    \n",
    "\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from Models_routines import *\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import inspect\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import Models_routines as module\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import layers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import models\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import time\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'lr': hp.choice('lr', [10**-4, 10**-3, 10**-2]),\n",
      "        'batch_size': hp.choice('batch_size', [32, 64]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: csv_dir =  root_dir +\"/DataNew4/CSV/\"   \n",
      "  3: (dftrain, dfval, dftest) = read_dataframes(csv_dir)\n",
      "  4: height_imag = 150 \n",
      "  5: width_imag = 150\n",
      "  6: x_train  = load_images_tf(dftrain,height_imag,width_imag)\n",
      "  7: x_val    = load_images_tf(dfval,height_imag,width_imag)\n",
      "  8: x_test   = load_images_tf(dftest,height_imag,width_imag)\n",
      "  9: y_train  = create_label_tensor(dftrain)\n",
      " 10: y_val    = create_label_tensor(dfval)\n",
      " 11: y_test   = create_label_tensor(dftest)\n",
      " 12: \n",
      " 13: \n",
      " 14: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     model = models.Sequential ()\n",
      "   5:     model.add(layers.Conv2D(64, (3,3), activation='relu', input_shape=(150,150,3)))\n",
      "   6:     model.add(layers.MaxPooling2D((2,2)))\n",
      "   7:     model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
      "   8:     model.add(layers.MaxPooling2D((2,2)))\n",
      "   9:     model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
      "  10:     model.add(layers.MaxPooling2D((2,2)))\n",
      "  11:  \n",
      "  12:     model.add(layers.Flatten())\n",
      "  13:     model.add(layers.Dense(512, activation='relu'))\n",
      "  14:     model.add(layers.Dropout(space['Dropout']))      \n",
      "  15:     model.add(layers.Dense(1, activation='sigmoid'))\n",
      "  16:     \n",
      "  17: \n",
      "  18:     \n",
      "  19:     adam = keras.optimizers.Adam(lr=space['lr'])\n",
      "  20: \n",
      "  21:     optim = adam\n",
      "  22:     \n",
      "  23:     \n",
      "  24:     model.compile ( loss='binary_crossentropy',\n",
      "  25:                optimizer = optim,\n",
      "  26:                metrics= ['acc'])\n",
      "  27:     early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
      "  28:     \n",
      "  29:     epochs = 100\n",
      "  30:     \n",
      "  31:     result = model.fit(x_train, y_train,\n",
      "  32:                       batch_size=space['batch_size'],\n",
      "  33:                       epochs=100,\n",
      "  34:                       verbose=2,\n",
      "  35:                       validation_data=(x_val, y_val),\n",
      "  36:                       callbacks=[early_stopping])\n",
      "  37: \n",
      "  38:     \n",
      "  39: \n",
      "  40:     validation_acc = np.amax(result.history['val_acc']) \n",
      "  41:     print('Best validation acc of epoch:', validation_acc)\n",
      "  42:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  43: \n",
      "/home/valborsf/Documents/UOC/PFMProject/DataNew4/CSV/\n",
      "Executing op ReadFile in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DecodeJpeg in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ExpandDims in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ResizeBilinear in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Squeeze in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "(2100, 150, 150, 3)\n",
      "(700, 150, 150, 3)\n",
      "(700, 150, 150, 3)\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:Large dropout rate: 0.651797 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Train on 2100 samples, validate on 700 samples     \n",
      "Epoch 1/100                                        \n",
      "Executing op __inference_keras_scratch_graph_40125 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op __inference_keras_scratch_graph_40225 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      " - 5s - loss: 4.0329 - acc: 0.5005 - val_loss: 0.6929 - val_acc: 0.5157\n",
      "\n",
      "Epoch 2/100                                        \n",
      " - 2s - loss: 0.6972 - acc: 0.4929 - val_loss: 0.6931 - val_acc: 0.5157\n",
      "\n",
      "Epoch 3/100                                        \n",
      " - 2s - loss: 0.6939 - acc: 0.5029 - val_loss: 0.6929 - val_acc: 0.5157\n",
      "\n",
      "Epoch 4/100                                        \n",
      " - 2s - loss: 0.6935 - acc: 0.4967 - val_loss: 0.6930 - val_acc: 0.5157\n",
      "\n",
      "Epoch 5/100                                        \n",
      " - 2s - loss: 0.6927 - acc: 0.5143 - val_loss: 0.6931 - val_acc: 0.5157\n",
      "\n",
      "Best validation acc of epoch:                      \n",
      "0.5157142877578735                                 \n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      " 20%|██        | 1/5 [00:15<01:00, 15.24s/it, best loss: -0.5157142877578735]WARNING:tensorflow:Large dropout rate: 0.912829 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Train on 2100 samples, validate on 700 samples                               \n",
      "Epoch 1/100                                                                  \n",
      "Executing op __inference_keras_scratch_graph_43186 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op __inference_keras_scratch_graph_43286 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      " - 4s - loss: 0.7090 - acc: 0.5286 - val_loss: 0.6639 - val_acc: 0.6571      \n",
      "\n",
      "Epoch 2/100                                                                  \n",
      " - 3s - loss: 0.6672 - acc: 0.5876 - val_loss: 0.6272 - val_acc: 0.6343      \n",
      "\n",
      "Epoch 3/100                                                                  \n",
      " - 3s - loss: 0.6326 - acc: 0.6367 - val_loss: 0.5874 - val_acc: 0.6714      \n",
      "\n",
      "Epoch 4/100                                                                  \n",
      " - 3s - loss: 0.6176 - acc: 0.6448 - val_loss: 0.5768 - val_acc: 0.6900      \n",
      "\n",
      "Epoch 5/100                                                                  \n",
      " - 3s - loss: 0.5917 - acc: 0.6571 - val_loss: 0.5559 - val_acc: 0.6757      \n",
      "\n",
      "Epoch 6/100                                                                  \n",
      " - 3s - loss: 0.5878 - acc: 0.6652 - val_loss: 0.5577 - val_acc: 0.6657      \n",
      "\n",
      "Epoch 7/100                                                                  \n",
      " - 3s - loss: 0.5800 - acc: 0.6795 - val_loss: 0.5385 - val_acc: 0.7157      \n",
      "\n",
      "Epoch 8/100                                                                  \n",
      " - 3s - loss: 0.5699 - acc: 0.6929 - val_loss: 0.5622 - val_acc: 0.7057      \n",
      "\n",
      "Epoch 9/100                                                                  \n",
      " - 3s - loss: 0.5692 - acc: 0.6929 - val_loss: 0.5216 - val_acc: 0.7386      \n",
      "\n",
      "Epoch 10/100                                                                 \n",
      " - 3s - loss: 0.5698 - acc: 0.6686 - val_loss: 0.5467 - val_acc: 0.6914      \n",
      "\n",
      "Epoch 11/100                                                                 \n",
      " - 3s - loss: 0.5506 - acc: 0.6938 - val_loss: 0.5136 - val_acc: 0.7171      \n",
      "\n",
      "Epoch 12/100                                                                 \n",
      " - 3s - loss: 0.5604 - acc: 0.6919 - val_loss: 0.5219 - val_acc: 0.6971      \n",
      "\n",
      "Epoch 13/100                                                                 \n",
      " - 3s - loss: 0.5557 - acc: 0.7000 - val_loss: 0.5174 - val_acc: 0.7414      \n",
      "\n",
      "Epoch 14/100                                                                 \n",
      " - 3s - loss: 0.5470 - acc: 0.6952 - val_loss: 0.5141 - val_acc: 0.7457      \n",
      "\n",
      "Epoch 15/100                                                                 \n",
      " - 3s - loss: 0.5350 - acc: 0.7100 - val_loss: 0.5240 - val_acc: 0.7386      \n",
      "\n",
      "Best validation acc of epoch:                                                \n",
      "0.7457143068313599                                                           \n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Train on 2100 samples, validate on 700 samples                               \n",
      "Epoch 1/100                                                                  \n",
      "Executing op __inference_keras_scratch_graph_52887 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op __inference_keras_scratch_graph_52987 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      " - 3s - loss: 0.7085 - acc: 0.5667 - val_loss: 0.5846 - val_acc: 0.6486      \n",
      "\n",
      "Epoch 2/100                                                                  \n",
      " - 3s - loss: 0.6810 - acc: 0.5652 - val_loss: 0.6891 - val_acc: 0.4843      \n",
      "\n",
      "Epoch 3/100                                                                  \n",
      " - 3s - loss: 0.6809 - acc: 0.5657 - val_loss: 0.6617 - val_acc: 0.5886      \n",
      "\n",
      "Epoch 4/100                                                                  \n",
      " - 3s - loss: 0.6313 - acc: 0.6438 - val_loss: 0.5815 - val_acc: 0.6500      \n",
      "\n",
      "Epoch 5/100                                                                  \n",
      " - 3s - loss: 0.6528 - acc: 0.6024 - val_loss: 0.6374 - val_acc: 0.5829      \n",
      "\n",
      "Epoch 6/100                                                                  \n",
      " - 3s - loss: 0.5843 - acc: 0.6805 - val_loss: 0.5616 - val_acc: 0.6986      \n",
      "\n",
      "Epoch 7/100                                                                  \n",
      " - 3s - loss: 0.6067 - acc: 0.6571 - val_loss: 0.5550 - val_acc: 0.6643      \n",
      "\n",
      "Epoch 8/100                                                                  \n",
      " - 3s - loss: 0.5643 - acc: 0.6862 - val_loss: 0.6313 - val_acc: 0.6329      \n",
      "\n",
      "Epoch 9/100                                                                  \n",
      " - 3s - loss: 0.5731 - acc: 0.6700 - val_loss: 0.5409 - val_acc: 0.6986      \n",
      "\n",
      "Epoch 10/100                                                                 \n",
      " - 3s - loss: 0.5463 - acc: 0.6952 - val_loss: 0.5992 - val_acc: 0.6843      \n",
      "\n",
      "Epoch 11/100                                                                 \n",
      " - 3s - loss: 0.5332 - acc: 0.7162 - val_loss: 0.5528 - val_acc: 0.7243      \n",
      "\n",
      "Epoch 12/100                                                                 \n",
      " - 3s - loss: 0.5129 - acc: 0.7300 - val_loss: 0.5353 - val_acc: 0.7457      \n",
      "\n",
      "Epoch 13/100                                                                 \n",
      " - 3s - loss: 0.4815 - acc: 0.7443 - val_loss: 0.6064 - val_acc: 0.6986      \n",
      "\n",
      "Epoch 14/100                                                                 \n",
      " - 3s - loss: 0.4679 - acc: 0.7586 - val_loss: 0.6470 - val_acc: 0.6657      \n",
      "\n",
      "Epoch 15/100                                                                 \n",
      " - 3s - loss: 0.4362 - acc: 0.7776 - val_loss: 0.6457 - val_acc: 0.6743      \n",
      "\n",
      "Epoch 16/100                                                                 \n",
      " - 3s - loss: 0.4036 - acc: 0.7967 - val_loss: 0.6016 - val_acc: 0.7329      \n",
      "\n",
      "Best validation acc of epoch:                                                \n",
      "0.7457143068313599                                                           \n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      " 60%|██████    | 3/5 [01:42<00:59, 29.76s/it, best loss: -0.7457143068313599]WARNING:tensorflow:Large dropout rate: 0.535081 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Train on 2100 samples, validate on 700 samples                               \n",
      "Epoch 1/100                                                                  \n",
      "Executing op __inference_keras_scratch_graph_63120 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op __inference_keras_scratch_graph_63220 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      " - 3s - loss: 0.8502 - acc: 0.5171 - val_loss: 0.6806 - val_acc: 0.5129      \n",
      "\n",
      "Epoch 2/100                                                                  \n",
      " - 2s - loss: 0.6730 - acc: 0.5667 - val_loss: 0.6837 - val_acc: 0.4929      \n",
      "\n",
      "Epoch 3/100                                                                  \n",
      " - 2s - loss: 0.6780 - acc: 0.5771 - val_loss: 0.6334 - val_acc: 0.6743      \n",
      "\n",
      "Epoch 4/100                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 0.6975 - acc: 0.5433 - val_loss: 0.6836 - val_acc: 0.5714      \n",
      "\n",
      "Epoch 5/100                                                                  \n",
      " - 2s - loss: 0.6465 - acc: 0.5895 - val_loss: 0.6735 - val_acc: 0.4886      \n",
      "\n",
      "Epoch 6/100                                                                  \n",
      " - 2s - loss: 0.6691 - acc: 0.5914 - val_loss: 0.6030 - val_acc: 0.6814      \n",
      "\n",
      "Epoch 7/100                                                                  \n",
      " - 2s - loss: 0.6022 - acc: 0.6505 - val_loss: 0.5508 - val_acc: 0.7014      \n",
      "\n",
      "Epoch 8/100                                                                  \n",
      " - 2s - loss: 0.5861 - acc: 0.6662 - val_loss: 0.5474 - val_acc: 0.7043      \n",
      "\n",
      "Epoch 9/100                                                                  \n",
      " - 2s - loss: 0.5632 - acc: 0.6857 - val_loss: 0.5380 - val_acc: 0.7186      \n",
      "\n",
      "Epoch 10/100                                                                 \n",
      " - 2s - loss: 0.5794 - acc: 0.6786 - val_loss: 0.5619 - val_acc: 0.6829      \n",
      "\n",
      "Epoch 11/100                                                                 \n",
      " - 2s - loss: 0.5411 - acc: 0.6976 - val_loss: 0.5303 - val_acc: 0.7186      \n",
      "\n",
      "Epoch 12/100                                                                 \n",
      " - 2s - loss: 0.5533 - acc: 0.6967 - val_loss: 0.5446 - val_acc: 0.7214      \n",
      "\n",
      "Epoch 13/100                                                                 \n",
      " - 2s - loss: 0.5199 - acc: 0.7219 - val_loss: 0.5226 - val_acc: 0.7229      \n",
      "\n",
      "Epoch 14/100                                                                 \n",
      " - 2s - loss: 0.5120 - acc: 0.7229 - val_loss: 0.5447 - val_acc: 0.7200      \n",
      "\n",
      "Epoch 15/100                                                                 \n",
      " - 2s - loss: 0.5165 - acc: 0.7162 - val_loss: 0.5945 - val_acc: 0.6957      \n",
      "\n",
      "Epoch 16/100                                                                 \n",
      " - 2s - loss: 0.4864 - acc: 0.7490 - val_loss: 0.5810 - val_acc: 0.6743      \n",
      "\n",
      "Epoch 17/100                                                                 \n",
      " - 2s - loss: 0.4799 - acc: 0.7438 - val_loss: 0.5473 - val_acc: 0.7229      \n",
      "\n",
      "Best validation acc of epoch:                                                \n",
      "0.7228571176528931                                                           \n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Train on 2100 samples, validate on 700 samples                               \n",
      "Epoch 1/100                                                                  \n",
      "Executing op __inference_keras_scratch_graph_69397 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "Executing op __inference_keras_scratch_graph_69497 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      " - 2s - loss: 0.6946 - acc: 0.5495 - val_loss: 0.6489 - val_acc: 0.6014      \n",
      "\n",
      "Epoch 2/100                                                                  \n",
      " - 2s - loss: 0.6565 - acc: 0.5971 - val_loss: 0.6359 - val_acc: 0.6900      \n",
      "\n",
      "Epoch 3/100                                                                  \n",
      " - 2s - loss: 0.6110 - acc: 0.6448 - val_loss: 0.5960 - val_acc: 0.6386      \n",
      "\n",
      "Epoch 4/100                                                                  \n",
      " - 2s - loss: 0.5930 - acc: 0.6619 - val_loss: 0.5669 - val_acc: 0.7343      \n",
      "\n",
      "Epoch 5/100                                                                  \n",
      " - 2s - loss: 0.5616 - acc: 0.6990 - val_loss: 0.5464 - val_acc: 0.7000      \n",
      "\n",
      "Epoch 6/100                                                                  \n",
      " - 2s - loss: 0.5724 - acc: 0.6767 - val_loss: 0.5332 - val_acc: 0.7257      \n",
      "\n",
      "Epoch 7/100                                                                  \n",
      " - 2s - loss: 0.5404 - acc: 0.7143 - val_loss: 0.5204 - val_acc: 0.7557      \n",
      "\n",
      "Epoch 8/100                                                                  \n",
      " - 2s - loss: 0.5342 - acc: 0.7067 - val_loss: 0.5201 - val_acc: 0.7471      \n",
      "\n",
      "Epoch 9/100                                                                  \n",
      " - 2s - loss: 0.5314 - acc: 0.7062 - val_loss: 0.5078 - val_acc: 0.7543      \n",
      "\n",
      "Epoch 10/100                                                                 \n",
      " - 2s - loss: 0.5203 - acc: 0.7200 - val_loss: 0.4997 - val_acc: 0.7571      \n",
      "\n",
      "Epoch 11/100                                                                 \n",
      " - 2s - loss: 0.5109 - acc: 0.7248 - val_loss: 0.5009 - val_acc: 0.7414      \n",
      "\n",
      "Epoch 12/100                                                                 \n",
      " - 2s - loss: 0.5136 - acc: 0.7210 - val_loss: 0.4958 - val_acc: 0.7429      \n",
      "\n",
      "Epoch 13/100                                                                 \n",
      " - 2s - loss: 0.5005 - acc: 0.7410 - val_loss: 0.5379 - val_acc: 0.6957      \n",
      "\n",
      "Epoch 14/100                                                                 \n",
      " - 2s - loss: 0.4851 - acc: 0.7543 - val_loss: 0.4808 - val_acc: 0.7529      \n",
      "\n",
      "Epoch 15/100                                                                 \n",
      " - 2s - loss: 0.4776 - acc: 0.7505 - val_loss: 0.5268 - val_acc: 0.7286      \n",
      "\n",
      "Epoch 16/100                                                                 \n",
      " - 2s - loss: 0.4748 - acc: 0.7514 - val_loss: 0.4885 - val_acc: 0.7557      \n",
      "\n",
      "Epoch 17/100                                                                 \n",
      " - 2s - loss: 0.4607 - acc: 0.7633 - val_loss: 0.4779 - val_acc: 0.7614      \n",
      "\n",
      "Epoch 18/100                                                                 \n",
      " - 2s - loss: 0.4755 - acc: 0.7605 - val_loss: 0.4802 - val_acc: 0.7586      \n",
      "\n",
      "Epoch 19/100                                                                 \n",
      " - 2s - loss: 0.4480 - acc: 0.7748 - val_loss: 0.4800 - val_acc: 0.7686      \n",
      "\n",
      "Epoch 20/100                                                                 \n",
      " - 2s - loss: 0.4467 - acc: 0.7757 - val_loss: 0.4836 - val_acc: 0.7457      \n",
      "\n",
      "Epoch 21/100                                                                 \n",
      " - 2s - loss: 0.4515 - acc: 0.7652 - val_loss: 0.5451 - val_acc: 0.6771      \n",
      "\n",
      "Best validation acc of epoch:                                                \n",
      "0.7685714364051819                                                           \n",
      "100%|██████████| 5/5 [03:13<00:00, 38.62s/it, best loss: -0.7685714364051819]\n",
      "/home/valborsf/Documents/UOC/PFMProject/DataNew4/CSV/\n",
      "(2100, 150, 150, 3)\n",
      "(700, 150, 150, 3)\n",
      "(700, 150, 150, 3)\n",
      "Evalutation of best performing model:\n",
      "700/700 [==============================] - 0s 378us/step\n",
      "[0.5482312909194401, 0.6899999976158142]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dropout': 0.2330896882313117, 'batch_size': 64, 'lr': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          eval_space=True,\n",
    "                                          notebook_name='ModelK13_Hyperas_2')\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = data()\n",
    "\n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    print(best_model.evaluate(x_test, y_test))\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    time.strftime('Time spent in TF loading :'\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results :\n",
    "# Gave an error for the elapsed time but results are :\n",
    "#    Dropout = '.23', batch_size = 64 lr: 10-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“gpu2”",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
