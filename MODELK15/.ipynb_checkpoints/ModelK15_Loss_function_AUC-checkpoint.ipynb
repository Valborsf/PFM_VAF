{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ur34g7Fbi5lr"
   },
   "source": [
    "# Notebook- Model K15 - Custom Loss Function AUC\n",
    "# Author : V.Albors   Date : 05.04.2020\n",
    "# Purpose : Create Custom Loss Function \n",
    "\n",
    "\n",
    "\n",
    "**Input** :  \n",
    "  * CSV files that identify the images to use as train and validation. CSV files are in directory csv_dir   \n",
    "  * Images from train and validation. Images are in directory : imag_dir  \n",
    "  * Saved model. Model is in directory : model_bin_dir  \n",
    "  \n",
    "**Output**:  \n",
    "  * Download of the model trained with train dataset - \n",
    "  * Download the history of the model in order to be evaluated \n",
    "\n",
    "**Process**:  \n",
    " * Read Train and Validation images ( identified in the .csv files ) from the imag_dir directory   \n",
    " * Create a train and validation input & label tensors (no augmentation)\n",
    " * Define the architecture of model : \n",
    "                        \n",
    " * Train the model with the train dataset with callbacks (  ModuleCheckPoint , Early Stopping)\n",
    " * Save the trained model and history of the model in directory model_bin_dir \n",
    " * Paint the Accuracy and Loss curves\n",
    " * Create results : Metrics \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU') \n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "10.0\n",
      "7.6\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow version \n",
    "print(tf.__version__)\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "print(tf_build_info.cuda_version_number)\n",
    "# Cuda Version 9.0 in v1.10.0\n",
    "print(tf_build_info.cudnn_version_number)\n",
    "# CudNN 7 in v1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the model \n",
    "Model_directory = \"MODELK15\"\n",
    "Model_name = \"ModelK15_1\"\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confusion_ROC_AUC', 'create_column_tensor', 'create_label_tensor', 'create_val_test', 'define_dirs', 'extract_images_bm', 'extract_images_train', 'load_hist_model', 'load_images', 'load_images_tf', 'model_load', 'model_load_tf', 'model_load_tf_custom_loss', 'plot_save_acc_loss', 'print_network', 'process_clinical_info', 'read_dataframes', 'read_dataframes_tables', 'reproducible_results', 'save_model', 'save_model_no_opt', 'save_network_json', 'start', 'stop', 'to_one_hot', 'to_one_hot_words', 'xi_squared']\n"
     ]
    }
   ],
   "source": [
    "# Import routines\n",
    "import sys  \n",
    "subrc_dir = \"/home/valborsf/Documents/UOC/PFMProject/\"\n",
    "\n",
    "sys.path.append(subrc_dir)  \n",
    "from  Models_routines import *\n",
    "import inspect\n",
    "\n",
    "# List functions inside the module\n",
    "import Models_routines as module\n",
    "functions = inspect.getmembers(module, inspect.isfunction)\n",
    "lsfunctions = [item[0] for item in functions]\n",
    "print ( lsfunctions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible results \n",
    "reproducible_results ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "(root_dir,json_dir,imag_dir,csv_dir,model_json_dir,model_bin_dir,results_dir,Tensor_dir) = define_dirs(Model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset without SONIC disturbing images\n",
    "json_dir =  root_dir +\"/DataNew/ALL_JSON/\"                # .json dir images\n",
    "imag_dir =  root_dir +\"/DataNew/ALL_IMAGES/\"              # .png dir - images\n",
    "\n",
    "# directories for  CSV's\n",
    "csv_dir =  root_dir +\"/DataNew4/CSV/\"                      # .csv dir - dftrain, dfval, dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/valborsf/Documents/UOC/PFMProject/DataNew4/CSV/\n"
     ]
    }
   ],
   "source": [
    "# Load train,validation & Test \n",
    "(dftrain, dfval, dftest) = read_dataframes(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label tensor\n",
    "train_label_tensor = create_label_tensor(dftrain)\n",
    "val_label_tensor = create_label_tensor(dfval)\n",
    "#test_label_tensor = create_label_tensor(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 150, 150, 3)\n",
      "(700, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors from images\n",
    "# Load Images \n",
    "height_imag = 150 \n",
    "width_imag = 150\n",
    "# This step is very time consuming !!!!!!!\n",
    "train_image_tensor  = load_images_tf(dftrain,height_imag,width_imag)\n",
    "val_image_tensor  = load_images_tf(dfval,height_imag,width_imag)\n",
    "#test_image_tensor  = load_images(dftest,height_imag,width_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 150, 150, 3)\n",
      "4\n",
      "(10, 150, 150, 3)\n",
      "4\n",
      "[0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      "(10,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# This part is to make trials with less samples \n",
    "print ( train_image_tensor.shape)\n",
    "print ( train_image_tensor.ndim)\n",
    "slice_10_pictures = train_image_tensor[0:10]\n",
    "slice_10_labels = train_label_tensor [0:10]\n",
    "val_10_pictures = val_image_tensor[0:10]\n",
    "val_10_labels = val_label_tensor [0:10]\n",
    "print ( slice_10_pictures.shape)\n",
    "print ( slice_10_pictures.ndim)\n",
    "print ( slice_10_labels)\n",
    "print ( slice_10_labels.shape)\n",
    "print ( slice_10_labels.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Model 1 : Image to Predict Melanoma\n",
    "\n",
    "image_inputs = Input(shape=(height_imag,width_imag,3))\n",
    "m2 = layers.Conv2D(64, (3,3), activation='relu')(image_inputs)\n",
    "m3 = layers.MaxPooling2D((2,2))(m2)\n",
    "m4 = layers.Conv2D(32, (3,3),  activation='relu')(m3)\n",
    "m5 = layers.MaxPooling2D((2,2))(m4)\n",
    "m6 = layers.Conv2D(128, (3,3), activation='relu')(m5)\n",
    "m7 = layers.MaxPooling2D((2,2))(m6)\n",
    "m8 = layers.Flatten()(m7)\n",
    "m9 = layers.Dense (512, activation='relu')(m8)\n",
    "m10 = layers.Dropout(0.23)(m9)\n",
    "benign_malign = layers.Dense (1, activation='sigmoid')(m10)\n",
    "\n",
    "\n",
    "# Model instantiation\n",
    "model = Model(image_inputs, benign_malign)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36992)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               18940416  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 18,998,177\n",
      "Trainable params: 18,998,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Network \n",
    "print_network (results_dir, model, Model_name)\n",
    "#Save Network \n",
    "save_network_json (model_json_dir, model, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "#https://github.com/tflearn/tflearn/issues/1028\n",
    "def roc_auc_score(y_pred, y_true):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    Arguments:\n",
    "        y_pred: `Tensor`. Predicted values.\n",
    "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"RocAucScore\"):\n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "# original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.2\n",
    "        p     = 3\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "        return tf.reduce_sum(tf.pow(-masked, p))\n",
    "\n",
    "def roc_auc_score_loss(y_true, y_pred):\n",
    "    auc = roc_auc_score(y_pred, y_true)     # Note y_true & y_pred are passed in dif order in keras and tflearn\n",
    "    tf.print(' AUC Loss: ', auc )\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compile\n",
    "from tensorflow.keras import optimizers\n",
    "model.compile(loss=roc_auc_score_loss,\n",
    "               optimizer = optimizers.Adam(lr=1e-4),\n",
    "#               metrics= [])\n",
    "               metrics= ['acc', roc_auc_score_loss])\n",
    "#               metrics= [roc_auc_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks_list = [\n",
    "# EarlyStopping when the model does not improve in loss\n",
    "\n",
    "         tf.keras.callbacks.EarlyStopping (\n",
    "#             monitor = 'roc_auc_score_loss',  # Early stop with roc auc\n",
    "             monitor = 'val_loss',             # Early stop with val _loss = roc auc \n",
    "             verbose=1,                        # log when finishes\n",
    "             patience = 4,),                   # Interrupt if acc no improve in 4 epochs\n",
    "\n",
    "#  ModelCheckpoint to store the weights of the best performing epoch. \n",
    "    \n",
    "         tf.keras.callbacks.ModelCheckpoint(filepath=model_bin_dir+\"Best_weights\"+Model_name+\".hdf5\", \n",
    "             monitor = 'val_loss', # Won't overwritte the model file unless val_loss has\n",
    "#             monitor = 'roc_auc_score_loss', # Won't overwritte the model file unless val_loss has\n",
    "             verbose=1,            # improve \n",
    "             save_best_only=True),\n",
    "         \n",
    "#         keras.callbacks.TensorBoard(\n",
    "#             log_dir =  Tensor_dir, \n",
    "#            histogram_freq = 1,\n",
    "#            )\n",
    "#        tf.keras.callbacks.ProgbarLogger(count_mode='samples')             # Display of log show samples seen \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2100 samples, validate on 700 samples\n",
      "Epoch 1/100\n",
      " AUC Loss:  31.8575268\n",
      " AUC Loss:  31.8575268\n",
      " 128/2100 [>.............................] - ETA: 44s - loss: 31.8575 - acc: 0.5156 - roc_auc_score_loss: 31.8575 AUC Loss:  31.7114372\n",
      " AUC Loss:  31.7114372\n",
      " 256/2100 [==>...........................] - ETA: 21s - loss: 31.7845 - acc: 0.5117 - roc_auc_score_loss: 31.7845 AUC Loss:  31.3886395\n",
      " AUC Loss:  31.3886395\n",
      " 384/2100 [====>.........................] - ETA: 13s - loss: 31.6525 - acc: 0.5130 - roc_auc_score_loss: 31.6525 AUC Loss:  33.0672073\n",
      " AUC Loss:  33.0672073\n",
      " 512/2100 [======>.......................] - ETA: 9s - loss: 32.0062 - acc: 0.5039 - roc_auc_score_loss: 32.0062  AUC Loss:  30.7512741\n",
      " AUC Loss:  30.7512741\n",
      " 640/2100 [========>.....................] - ETA: 7s - loss: 31.7552 - acc: 0.5063 - roc_auc_score_loss: 31.7552 AUC Loss:  31.0407982\n",
      " AUC Loss:  31.0407982\n",
      " 768/2100 [=========>....................] - ETA: 5s - loss: 31.6361 - acc: 0.4961 - roc_auc_score_loss: 31.6361 AUC Loss:  30.1741581\n",
      " AUC Loss:  30.1741581\n",
      " 896/2100 [===========>..................] - ETA: 4s - loss: 31.4273 - acc: 0.5000 - roc_auc_score_loss: 31.4273 AUC Loss:  25.6544647\n",
      " AUC Loss:  25.6544647\n",
      "1024/2100 [=============>................] - ETA: 3s - loss: 30.7057 - acc: 0.4941 - roc_auc_score_loss: 30.7057 AUC Loss:  29.138813\n",
      " AUC Loss:  29.138813\n",
      "1152/2100 [===============>..............] - ETA: 3s - loss: 30.5316 - acc: 0.4948 - roc_auc_score_loss: 30.5316 AUC Loss:  31.2956848\n",
      " AUC Loss:  31.2956848\n",
      "1280/2100 [=================>............] - ETA: 2s - loss: 30.6080 - acc: 0.4977 - roc_auc_score_loss: 30.6080 AUC Loss:  28.4918652\n",
      " AUC Loss:  28.4918652\n",
      "1408/2100 [===================>..........] - ETA: 1s - loss: 30.4156 - acc: 0.4936 - roc_auc_score_loss: 30.4156 AUC Loss:  31.4995728\n",
      " AUC Loss:  31.4995728\n",
      "1536/2100 [====================>.........] - ETA: 1s - loss: 30.5060 - acc: 0.4954 - roc_auc_score_loss: 30.5060 AUC Loss:  29.0577049\n",
      " AUC Loss:  29.0577049\n",
      "1664/2100 [======================>.......] - ETA: 1s - loss: 30.3945 - acc: 0.4970 - roc_auc_score_loss: 30.3946 AUC Loss:  24.8732662\n",
      " AUC Loss:  24.8732662\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 30.0002 - acc: 0.5017 - roc_auc_score_loss: 30.0002 AUC Loss:  28.7144394\n",
      " AUC Loss:  28.7144394\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 29.9145 - acc: 0.5021 - roc_auc_score_loss: 29.9145 AUC Loss:  23.6869678\n",
      " AUC Loss:  23.6869678\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 29.5252 - acc: 0.5054 - roc_auc_score_loss: 29.5252 AUC Loss:  3.61114168\n",
      " AUC Loss:  3.61114168\n",
      " AUC Loss:  26.8061409\n",
      " AUC Loss:  26.8061409\n",
      " AUC Loss:  22.8975239\n",
      " AUC Loss:  22.8975239\n",
      " AUC Loss:  23.2900658\n",
      " AUC Loss:  23.2900658\n",
      " AUC Loss:  23.9945221\n",
      " AUC Loss:  23.9945221\n",
      " AUC Loss:  24.3296604\n",
      " AUC Loss:  24.3296604\n",
      " AUC Loss:  5.61409521\n",
      " AUC Loss:  5.61409521\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 22.66506, saving model to /home/valborsf/Documents/UOC/PFMProject/MODELK15/BMODEL/Best_weightsModelK15_1.hdf5\n",
      "2100/2100 [==============================] - 7s 3ms/sample - loss: 28.8836 - acc: 0.5043 - roc_auc_score_loss: 28.0009 - val_loss: 22.6651 - val_acc: 0.5143 - val_roc_auc_score_loss: 21.1553\n",
      "Epoch 2/100\n",
      " AUC Loss:  25.6601143\n",
      " AUC Loss:  25.6601143\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 25.6601 - acc: 0.5234 - roc_auc_score_loss: 25.6601 AUC Loss:  21.9472809\n",
      " AUC Loss:  21.9472809\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 23.8037 - acc: 0.5156 - roc_auc_score_loss: 23.8037 AUC Loss:  25.5777664\n",
      " AUC Loss:  25.5777664\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 24.3951 - acc: 0.5078 - roc_auc_score_loss: 24.3951 AUC Loss:  29.7757931\n",
      " AUC Loss:  29.7757931\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 25.7402 - acc: 0.5117 - roc_auc_score_loss: 25.7402 AUC Loss:  19.4910641\n",
      " AUC Loss:  19.4910641\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 24.4904 - acc: 0.5266 - roc_auc_score_loss: 24.4904 AUC Loss:  27.8962822\n",
      " AUC Loss:  27.8962822\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 25.0581 - acc: 0.5312 - roc_auc_score_loss: 25.0581 AUC Loss:  21.8647804\n",
      " AUC Loss:  21.8647804\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 24.6019 - acc: 0.5558 - roc_auc_score_loss: 24.6019 AUC Loss:  26.28298\n",
      " AUC Loss:  26.28298\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 24.8120 - acc: 0.5527 - roc_auc_score_loss: 24.8120 AUC Loss:  21.0588303\n",
      " AUC Loss:  21.0588303\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 24.3950 - acc: 0.5564 - roc_auc_score_loss: 24.3950 AUC Loss:  24.5609\n",
      " AUC Loss:  24.5609\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 24.4116 - acc: 0.5500 - roc_auc_score_loss: 24.4116 AUC Loss:  23.0231152\n",
      " AUC Loss:  23.0231152\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 24.2854 - acc: 0.5511 - roc_auc_score_loss: 24.2854 AUC Loss:  21.9210835\n",
      " AUC Loss:  21.9210835\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 24.0883 - acc: 0.5605 - roc_auc_score_loss: 24.0883 AUC Loss:  23.0523815\n",
      " AUC Loss:  23.0523815\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 24.0086 - acc: 0.5607 - roc_auc_score_loss: 24.0086 AUC Loss:  23.7623787\n",
      " AUC Loss:  23.7623787\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 23.9911 - acc: 0.5608 - roc_auc_score_loss: 23.9911 AUC Loss:  23.0731125\n",
      " AUC Loss:  23.0731125\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 23.9299 - acc: 0.5635 - roc_auc_score_loss: 23.9299 AUC Loss:  23.826458\n",
      " AUC Loss:  23.826458\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 23.9234 - acc: 0.5679 - roc_auc_score_loss: 23.9234 AUC Loss:  3.82805753\n",
      " AUC Loss:  3.82805753\n",
      " AUC Loss:  24.2908115\n",
      " AUC Loss:  24.2908115\n",
      " AUC Loss:  20.2555561\n",
      " AUC Loss:  20.2555561\n",
      " AUC Loss:  19.9883308\n",
      " AUC Loss:  19.9883308\n",
      " AUC Loss:  19.6308918\n",
      " AUC Loss:  19.6308918\n",
      " AUC Loss:  19.4826164\n",
      " AUC Loss:  19.4826164\n",
      " AUC Loss:  5.14833355\n",
      " AUC Loss:  5.14833355\n",
      "\n",
      "Epoch 00002: val_loss improved from 22.66506 to 19.39410, saving model to /home/valborsf/Documents/UOC/PFMProject/MODELK15/BMODEL/Best_weightsModelK15_1.hdf5\n",
      "2100/2100 [==============================] - 3s 1ms/sample - loss: 23.4258 - acc: 0.5695 - roc_auc_score_loss: 22.7413 - val_loss: 19.3941 - val_acc: 0.6557 - val_roc_auc_score_loss: 18.1328\n",
      "Epoch 3/100\n",
      " AUC Loss:  19.9062729\n",
      " AUC Loss:  19.9062729\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 19.9063 - acc: 0.6328 - roc_auc_score_loss: 19.9063 AUC Loss:  18.0183525\n",
      " AUC Loss:  18.0183525\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 18.9623 - acc: 0.6758 - roc_auc_score_loss: 18.9623 AUC Loss:  20.4535522\n",
      " AUC Loss:  20.4535522\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 19.4594 - acc: 0.6406 - roc_auc_score_loss: 19.4594 AUC Loss:  22.1862755\n",
      " AUC Loss:  22.1862755\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 20.1411 - acc: 0.6465 - roc_auc_score_loss: 20.1411 AUC Loss:  16.1270142\n",
      " AUC Loss:  16.1270142\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 19.3383 - acc: 0.6703 - roc_auc_score_loss: 19.3383 AUC Loss:  24.3278427\n",
      " AUC Loss:  24.3278427\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 20.1699 - acc: 0.6654 - roc_auc_score_loss: 20.1699 AUC Loss:  20.1564655\n",
      " AUC Loss:  20.1564655\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 20.1680 - acc: 0.6696 - roc_auc_score_loss: 20.1680 AUC Loss:  24.3082809\n",
      " AUC Loss:  24.3082809\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 20.6855 - acc: 0.6660 - roc_auc_score_loss: 20.6855 AUC Loss:  23.1346264\n",
      " AUC Loss:  23.1346264\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 20.9576 - acc: 0.6658 - roc_auc_score_loss: 20.9576 AUC Loss:  21.5884628\n",
      " AUC Loss:  21.5884628\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 21.0207 - acc: 0.6633 - roc_auc_score_loss: 21.0207 AUC Loss:  20.556591\n",
      " AUC Loss:  20.556591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408/2100 [===================>..........] - ETA: 0s - loss: 20.9785 - acc: 0.6683 - roc_auc_score_loss: 20.9785 AUC Loss:  17.4697914\n",
      " AUC Loss:  17.4697914\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 20.6861 - acc: 0.6738 - roc_auc_score_loss: 20.6861 AUC Loss:  24.1999111\n",
      " AUC Loss:  24.1999111\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 20.9564 - acc: 0.6659 - roc_auc_score_loss: 20.9564 AUC Loss:  20.4435196\n",
      " AUC Loss:  20.4435196\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 20.9198 - acc: 0.6663 - roc_auc_score_loss: 20.9198 AUC Loss:  16.4601822\n",
      " AUC Loss:  16.4601822\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 20.6225 - acc: 0.6693 - roc_auc_score_loss: 20.6225 AUC Loss:  19.8872452\n",
      " AUC Loss:  19.8872452\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 20.5765 - acc: 0.6680 - roc_auc_score_loss: 20.5765 AUC Loss:  3.32696986\n",
      " AUC Loss:  3.32696986\n",
      " AUC Loss:  22.2015362\n",
      " AUC Loss:  22.2015362\n",
      " AUC Loss:  19.399128\n",
      " AUC Loss:  19.399128\n",
      " AUC Loss:  18.1182404\n",
      " AUC Loss:  18.1182404\n",
      " AUC Loss:  17.9744816\n",
      " AUC Loss:  17.9744816\n",
      " AUC Loss:  17.4998665\n",
      " AUC Loss:  17.4998665\n",
      " AUC Loss:  4.45842695\n",
      " AUC Loss:  4.45842695\n",
      "\n",
      "Epoch 00003: val_loss improved from 19.39410 to 17.78892, saving model to /home/valborsf/Documents/UOC/PFMProject/MODELK15/BMODEL/Best_weightsModelK15_1.hdf5\n",
      "2100/2100 [==============================] - 3s 1ms/sample - loss: 20.1494 - acc: 0.6705 - roc_auc_score_loss: 19.5618 - val_loss: 17.7889 - val_acc: 0.6986 - val_roc_auc_score_loss: 16.6086\n",
      "Epoch 4/100\n",
      " AUC Loss:  13.9869566\n",
      " AUC Loss:  13.9869566\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 13.9870 - acc: 0.7969 - roc_auc_score_loss: 13.9870 AUC Loss:  17.9795876\n",
      " AUC Loss:  17.9795876\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 15.9833 - acc: 0.7773 - roc_auc_score_loss: 15.9833 AUC Loss:  24.1767178\n",
      " AUC Loss:  24.1767178\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 18.7144 - acc: 0.7240 - roc_auc_score_loss: 18.7144 AUC Loss:  19.8630486\n",
      " AUC Loss:  19.8630486\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 19.0016 - acc: 0.7266 - roc_auc_score_loss: 19.0016 AUC Loss:  13.8212299\n",
      " AUC Loss:  13.8212299\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 17.9655 - acc: 0.7406 - roc_auc_score_loss: 17.9655 AUC Loss:  20.2104568\n",
      " AUC Loss:  20.2104568\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 18.3397 - acc: 0.7305 - roc_auc_score_loss: 18.3397 AUC Loss:  18.820055\n",
      " AUC Loss:  18.820055\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 18.4083 - acc: 0.7210 - roc_auc_score_loss: 18.4083 AUC Loss:  19.6707153\n",
      " AUC Loss:  19.6707153\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 18.5661 - acc: 0.7207 - roc_auc_score_loss: 18.5661 AUC Loss:  19.9423084\n",
      " AUC Loss:  19.9423084\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 18.7190 - acc: 0.7170 - roc_auc_score_loss: 18.7190 AUC Loss:  19.442234\n",
      " AUC Loss:  19.442234\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 18.7913 - acc: 0.7117 - roc_auc_score_loss: 18.7913 AUC Loss:  18.7553883\n",
      " AUC Loss:  18.7553883\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 18.7881 - acc: 0.7138 - roc_auc_score_loss: 18.7881 AUC Loss:  19.4708767\n",
      " AUC Loss:  19.4708767\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 18.8450 - acc: 0.7122 - roc_auc_score_loss: 18.8450 AUC Loss:  21.2503643\n",
      " AUC Loss:  21.2503643\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 19.0300 - acc: 0.7049 - roc_auc_score_loss: 19.0300 AUC Loss:  15.1540298\n",
      " AUC Loss:  15.1540298\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 18.7531 - acc: 0.6948 - roc_auc_score_loss: 18.7531 AUC Loss:  19.0071831\n",
      " AUC Loss:  19.0071831\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 18.7701 - acc: 0.6839 - roc_auc_score_loss: 18.7701 AUC Loss:  13.2835121\n",
      " AUC Loss:  13.2835121\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 18.4272 - acc: 0.6777 - roc_auc_score_loss: 18.4272 AUC Loss:  2.69142294\n",
      " AUC Loss:  2.69142294\n",
      " AUC Loss:  22.5172024\n",
      " AUC Loss:  22.5172024\n",
      " AUC Loss:  19.8816528\n",
      " AUC Loss:  19.8816528\n",
      " AUC Loss:  17.6553612\n",
      " AUC Loss:  17.6553612\n",
      " AUC Loss:  18.2089348\n",
      " AUC Loss:  18.2089348\n",
      " AUC Loss:  17.2685776\n",
      " AUC Loss:  17.2685776\n",
      " AUC Loss:  4.14938354\n",
      " AUC Loss:  4.14938354\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 17.78892\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 18.0375 - acc: 0.6752 - roc_auc_score_loss: 17.5015 - val_loss: 17.8243 - val_acc: 0.5700 - val_roc_auc_score_loss: 16.6135\n",
      "Epoch 5/100\n",
      " AUC Loss:  15.7691469\n",
      " AUC Loss:  15.7691469\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 15.7691 - acc: 0.5469 - roc_auc_score_loss: 15.7691 AUC Loss:  17.8592\n",
      " AUC Loss:  17.8592\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 16.8142 - acc: 0.5820 - roc_auc_score_loss: 16.8142 AUC Loss:  19.5604858\n",
      " AUC Loss:  19.5604858\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 17.7296 - acc: 0.6198 - roc_auc_score_loss: 17.7296 AUC Loss:  23.1524773\n",
      " AUC Loss:  23.1524773\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 19.0853 - acc: 0.6406 - roc_auc_score_loss: 19.0853 AUC Loss:  15.6327209\n",
      " AUC Loss:  15.6327209\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 18.3948 - acc: 0.6453 - roc_auc_score_loss: 18.3948 AUC Loss:  16.9649544\n",
      " AUC Loss:  16.9649544\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 18.1565 - acc: 0.6471 - roc_auc_score_loss: 18.1565 AUC Loss:  15.4719772\n",
      " AUC Loss:  15.4719772\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 17.7730 - acc: 0.6540 - roc_auc_score_loss: 17.7730 AUC Loss:  19.5936699\n",
      " AUC Loss:  19.5936699\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 18.0006 - acc: 0.6416 - roc_auc_score_loss: 18.0006 AUC Loss:  18.6153526\n",
      " AUC Loss:  18.6153526\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 18.0689 - acc: 0.6458 - roc_auc_score_loss: 18.0689 AUC Loss:  17.1520748\n",
      " AUC Loss:  17.1520748\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 17.9772 - acc: 0.6523 - roc_auc_score_loss: 17.9772 AUC Loss:  14.0813293\n",
      " AUC Loss:  14.0813293\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 17.6230 - acc: 0.6634 - roc_auc_score_loss: 17.6230 AUC Loss:  17.3199291\n",
      " AUC Loss:  17.3199291\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 17.5978 - acc: 0.6673 - roc_auc_score_loss: 17.5978 AUC Loss:  15.431221\n",
      " AUC Loss:  15.431221\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 17.4311 - acc: 0.6707 - roc_auc_score_loss: 17.4311 AUC Loss:  18.9402847\n",
      " AUC Loss:  18.9402847\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 17.5389 - acc: 0.6769 - roc_auc_score_loss: 17.5389 AUC Loss:  16.0751076\n",
      " AUC Loss:  16.0751076\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 17.4413 - acc: 0.6802 - roc_auc_score_loss: 17.4413 AUC Loss:  15.1520462\n",
      " AUC Loss:  15.1520462\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 17.2982 - acc: 0.6870 - roc_auc_score_loss: 17.2982 AUC Loss:  2.44536924\n",
      " AUC Loss:  2.44536924\n",
      " AUC Loss:  19.4370422\n",
      " AUC Loss:  19.4370422\n",
      " AUC Loss:  17.5680485\n",
      " AUC Loss:  17.5680485\n",
      " AUC Loss:  16.0798035\n",
      " AUC Loss:  16.0798035\n",
      " AUC Loss:  14.7895956\n",
      " AUC Loss:  14.7895956\n",
      " AUC Loss:  14.9127893\n",
      " AUC Loss:  14.9127893\n",
      " AUC Loss:  3.70048928\n",
      " AUC Loss:  3.70048928\n",
      "\n",
      "Epoch 00005: val_loss improved from 17.78892 to 15.45543, saving model to /home/valborsf/Documents/UOC/PFMProject/MODELK15/BMODEL/Best_weightsModelK15_1.hdf5\n",
      "2100/2100 [==============================] - 3s 1ms/sample - loss: 16.9305 - acc: 0.6886 - roc_auc_score_loss: 16.4245 - val_loss: 15.4554 - val_acc: 0.7200 - val_roc_auc_score_loss: 14.4146\n",
      "Epoch 6/100\n",
      " AUC Loss:  14.0346546\n",
      " AUC Loss:  14.0346546\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 14.0347 - acc: 0.7500 - roc_auc_score_loss: 14.0347 AUC Loss:  14.4688473\n",
      " AUC Loss:  14.4688473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 256/2100 [==>...........................] - ETA: 1s - loss: 14.2518 - acc: 0.7383 - roc_auc_score_loss: 14.2518 AUC Loss:  14.4888439\n",
      " AUC Loss:  14.4888439\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 14.3308 - acc: 0.7161 - roc_auc_score_loss: 14.3308 AUC Loss:  15.4007072\n",
      " AUC Loss:  15.4007072\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 14.5983 - acc: 0.7109 - roc_auc_score_loss: 14.5983 AUC Loss:  15.6285915\n",
      " AUC Loss:  15.6285915\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 14.8043 - acc: 0.7125 - roc_auc_score_loss: 14.8043 AUC Loss:  15.4009056\n",
      " AUC Loss:  15.4009056\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 14.9038 - acc: 0.7135 - roc_auc_score_loss: 14.9038 AUC Loss:  17.3996296\n",
      " AUC Loss:  17.3996296\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 15.2603 - acc: 0.7076 - roc_auc_score_loss: 15.2603 AUC Loss:  13.3533792\n",
      " AUC Loss:  13.3533792\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 15.0219 - acc: 0.7031 - roc_auc_score_loss: 15.0219 AUC Loss:  16.1412354\n",
      " AUC Loss:  16.1412354\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 15.1463 - acc: 0.7031 - roc_auc_score_loss: 15.1463 AUC Loss:  24.5480804\n",
      " AUC Loss:  24.5480804\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 16.0865 - acc: 0.6977 - roc_auc_score_loss: 16.0865 AUC Loss:  13.1558847\n",
      " AUC Loss:  13.1558847\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 15.8201 - acc: 0.7045 - roc_auc_score_loss: 15.8201 AUC Loss:  20.5339203\n",
      " AUC Loss:  20.5339203\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 16.2129 - acc: 0.7005 - roc_auc_score_loss: 16.2129 AUC Loss:  22.3840065\n",
      " AUC Loss:  22.3840065\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 16.6876 - acc: 0.6941 - roc_auc_score_loss: 16.6876 AUC Loss:  14.1280546\n",
      " AUC Loss:  14.1280546\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 16.5048 - acc: 0.6869 - roc_auc_score_loss: 16.5048 AUC Loss:  17.9443207\n",
      " AUC Loss:  17.9443207\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 16.6007 - acc: 0.6792 - roc_auc_score_loss: 16.6007 AUC Loss:  17.5027447\n",
      " AUC Loss:  17.5027447\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 16.6571 - acc: 0.6768 - roc_auc_score_loss: 16.6571 AUC Loss:  3.16785407\n",
      " AUC Loss:  3.16785407\n",
      " AUC Loss:  19.4521141\n",
      " AUC Loss:  19.4521141\n",
      " AUC Loss:  17.9514446\n",
      " AUC Loss:  17.9514446\n",
      " AUC Loss:  15.9274521\n",
      " AUC Loss:  15.9274521\n",
      " AUC Loss:  15.1846094\n",
      " AUC Loss:  15.1846094\n",
      " AUC Loss:  15.3244534\n",
      " AUC Loss:  15.3244534\n",
      " AUC Loss:  3.57648182\n",
      " AUC Loss:  3.57648182\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 15.45543\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 16.3231 - acc: 0.6752 - roc_auc_score_loss: 15.8636 - val_loss: 15.6373 - val_acc: 0.7486 - val_roc_auc_score_loss: 14.5694\n",
      "Epoch 7/100\n",
      " AUC Loss:  16.1641426\n",
      " AUC Loss:  16.1641426\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 16.1641 - acc: 0.7656 - roc_auc_score_loss: 16.1641 AUC Loss:  17.5688248\n",
      " AUC Loss:  17.5688248\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 16.8665 - acc: 0.7188 - roc_auc_score_loss: 16.8665 AUC Loss:  18.007288\n",
      " AUC Loss:  18.007288\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 17.2468 - acc: 0.7083 - roc_auc_score_loss: 17.2468 AUC Loss:  15.4348049\n",
      " AUC Loss:  15.4348049\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 16.7938 - acc: 0.7031 - roc_auc_score_loss: 16.7938 AUC Loss:  21.9869385\n",
      " AUC Loss:  21.9869385\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 17.8324 - acc: 0.6844 - roc_auc_score_loss: 17.8324 AUC Loss:  13.2263317\n",
      " AUC Loss:  13.2263317\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 17.0647 - acc: 0.7018 - roc_auc_score_loss: 17.0647 AUC Loss:  19.8135796\n",
      " AUC Loss:  19.8135796\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 17.4574 - acc: 0.6998 - roc_auc_score_loss: 17.4574 AUC Loss:  17.7367306\n",
      " AUC Loss:  17.7367306\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 17.4923 - acc: 0.7021 - roc_auc_score_loss: 17.4923 AUC Loss:  12.6271248\n",
      " AUC Loss:  12.6271248\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 16.9518 - acc: 0.7144 - roc_auc_score_loss: 16.9518 AUC Loss:  14.9276104\n",
      " AUC Loss:  14.9276104\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 16.7493 - acc: 0.7172 - roc_auc_score_loss: 16.7493 AUC Loss:  18.0578575\n",
      " AUC Loss:  18.0578575\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 16.8683 - acc: 0.7159 - roc_auc_score_loss: 16.8683 AUC Loss:  12.6650887\n",
      " AUC Loss:  12.6650887\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 16.5180 - acc: 0.7233 - roc_auc_score_loss: 16.5180 AUC Loss:  14.6500511\n",
      " AUC Loss:  14.6500511\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 16.3743 - acc: 0.7236 - roc_auc_score_loss: 16.3743 AUC Loss:  13.5309181\n",
      " AUC Loss:  13.5309181\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 16.1712 - acc: 0.7243 - roc_auc_score_loss: 16.1712 AUC Loss:  13.1505775\n",
      " AUC Loss:  13.1505775\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 15.9699 - acc: 0.7281 - roc_auc_score_loss: 15.9699 AUC Loss:  15.611475\n",
      " AUC Loss:  15.611475\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 15.9475 - acc: 0.7285 - roc_auc_score_loss: 15.9475 AUC Loss:  2.73929524\n",
      " AUC Loss:  2.73929524\n",
      " AUC Loss:  19.0780888\n",
      " AUC Loss:  19.0780888\n",
      " AUC Loss:  16.603651\n",
      " AUC Loss:  16.603651\n",
      " AUC Loss:  15.819829\n",
      " AUC Loss:  15.819829\n",
      " AUC Loss:  15.728632\n",
      " AUC Loss:  15.728632\n",
      " AUC Loss:  14.4244223\n",
      " AUC Loss:  14.4244223\n",
      " AUC Loss:  3.3120234\n",
      " AUC Loss:  3.3120234\n",
      "\n",
      "Epoch 00007: val_loss improved from 15.45543 to 15.21502, saving model to /home/valborsf/Documents/UOC/PFMProject/MODELK15/BMODEL/Best_weightsModelK15_1.hdf5\n",
      "2100/2100 [==============================] - 3s 1ms/sample - loss: 15.6204 - acc: 0.7276 - roc_auc_score_loss: 15.1705 - val_loss: 15.2150 - val_acc: 0.7514 - val_roc_auc_score_loss: 14.1611\n",
      "Epoch 8/100\n",
      " AUC Loss:  11.3572798\n",
      " AUC Loss:  11.3572798\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 11.3573 - acc: 0.8047 - roc_auc_score_loss: 11.3573 AUC Loss:  16.3743839\n",
      " AUC Loss:  16.3743839\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 13.8658 - acc: 0.7773 - roc_auc_score_loss: 13.8658 AUC Loss:  14.8290138\n",
      " AUC Loss:  14.8290138\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 14.1869 - acc: 0.7734 - roc_auc_score_loss: 14.1869 AUC Loss:  17.3442802\n",
      " AUC Loss:  17.3442802\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 14.9762 - acc: 0.7500 - roc_auc_score_loss: 14.9762 AUC Loss:  11.793148\n",
      " AUC Loss:  11.793148\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 14.3396 - acc: 0.7578 - roc_auc_score_loss: 14.3396 AUC Loss:  16.6063309\n",
      " AUC Loss:  16.6063309\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 14.7174 - acc: 0.7591 - roc_auc_score_loss: 14.7174 AUC Loss:  16.2912235\n",
      " AUC Loss:  16.2912235\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 14.9422 - acc: 0.7545 - roc_auc_score_loss: 14.9422 AUC Loss:  15.5227213\n",
      " AUC Loss:  15.5227213\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 15.0148 - acc: 0.7529 - roc_auc_score_loss: 15.0148 AUC Loss:  16.2572308\n",
      " AUC Loss:  16.2572308\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 15.1528 - acc: 0.7405 - roc_auc_score_loss: 15.1528 AUC Loss:  18.6300583\n",
      " AUC Loss:  18.6300583\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 15.5006 - acc: 0.7320 - roc_auc_score_loss: 15.5006 AUC Loss:  15.5725679\n",
      " AUC Loss:  15.5725679\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 15.5071 - acc: 0.7344 - roc_auc_score_loss: 15.5071 AUC Loss:  17.713028\n",
      " AUC Loss:  17.713028\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 15.6909 - acc: 0.7370 - roc_auc_score_loss: 15.6909 AUC Loss:  20.4386406\n",
      " AUC Loss:  20.4386406\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 16.0561 - acc: 0.7296 - roc_auc_score_loss: 16.0561 AUC Loss:  13.1579781\n",
      " AUC Loss:  13.1579781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792/2100 [========================>.....] - ETA: 0s - loss: 15.8491 - acc: 0.7327 - roc_auc_score_loss: 15.8491 AUC Loss:  13.1529751\n",
      " AUC Loss:  13.1529751\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 15.6694 - acc: 0.7328 - roc_auc_score_loss: 15.6694 AUC Loss:  14.1766949\n",
      " AUC Loss:  14.1766949\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 15.5761 - acc: 0.7358 - roc_auc_score_loss: 15.5761 AUC Loss:  2.58846474\n",
      " AUC Loss:  2.58846474\n",
      " AUC Loss:  18.8740635\n",
      " AUC Loss:  18.8740635\n",
      " AUC Loss:  17.8158722\n",
      " AUC Loss:  17.8158722\n",
      " AUC Loss:  15.5255051\n",
      " AUC Loss:  15.5255051\n",
      " AUC Loss:  15.8575191\n",
      " AUC Loss:  15.8575191\n",
      " AUC Loss:  14.7558756\n",
      " AUC Loss:  14.7558756\n",
      " AUC Loss:  3.34638929\n",
      " AUC Loss:  3.34638929\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 15.21502\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 15.2545 - acc: 0.7367 - roc_auc_score_loss: 14.8121 - val_loss: 15.4327 - val_acc: 0.7557 - val_roc_auc_score_loss: 14.3625\n",
      "Epoch 9/100\n",
      " AUC Loss:  16.2344646\n",
      " AUC Loss:  16.2344646\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 16.2345 - acc: 0.7266 - roc_auc_score_loss: 16.2345 AUC Loss:  13.0981102\n",
      " AUC Loss:  13.0981102\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 14.6663 - acc: 0.7617 - roc_auc_score_loss: 14.6663 AUC Loss:  12.0751152\n",
      " AUC Loss:  12.0751152\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 13.8026 - acc: 0.7682 - roc_auc_score_loss: 13.8026 AUC Loss:  13.7094126\n",
      " AUC Loss:  13.7094126\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 13.7793 - acc: 0.7695 - roc_auc_score_loss: 13.7793 AUC Loss:  18.6504898\n",
      " AUC Loss:  18.6504898\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 14.7535 - acc: 0.7531 - roc_auc_score_loss: 14.7535 AUC Loss:  13.1187401\n",
      " AUC Loss:  13.1187401\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 14.4811 - acc: 0.7474 - roc_auc_score_loss: 14.4811 AUC Loss:  12.4806786\n",
      " AUC Loss:  12.4806786\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 14.1953 - acc: 0.7433 - roc_auc_score_loss: 14.1953 AUC Loss:  13.1766882\n",
      " AUC Loss:  13.1766882\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 14.0680 - acc: 0.7314 - roc_auc_score_loss: 14.0680 AUC Loss:  16.5805225\n",
      " AUC Loss:  16.5805225\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 14.3471 - acc: 0.7205 - roc_auc_score_loss: 14.3471 AUC Loss:  15.429863\n",
      " AUC Loss:  15.429863\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 14.4554 - acc: 0.7203 - roc_auc_score_loss: 14.4554 AUC Loss:  13.8725643\n",
      " AUC Loss:  13.8725643\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 14.4024 - acc: 0.7237 - roc_auc_score_loss: 14.4024 AUC Loss:  15.17243\n",
      " AUC Loss:  15.17243\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 14.4666 - acc: 0.7279 - roc_auc_score_loss: 14.4666 AUC Loss:  16.0063763\n",
      " AUC Loss:  16.0063763\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 14.5850 - acc: 0.7278 - roc_auc_score_loss: 14.5850 AUC Loss:  11.0909767\n",
      " AUC Loss:  11.0909767\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 14.3355 - acc: 0.7305 - roc_auc_score_loss: 14.3355 AUC Loss:  13.6228247\n",
      " AUC Loss:  13.6228247\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 14.2880 - acc: 0.7302 - roc_auc_score_loss: 14.2880 AUC Loss:  16.5107288\n",
      " AUC Loss:  16.5107288\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 14.4269 - acc: 0.7290 - roc_auc_score_loss: 14.4269 AUC Loss:  1.71032441\n",
      " AUC Loss:  1.71032441\n",
      " AUC Loss:  19.5880527\n",
      " AUC Loss:  19.5880527\n",
      " AUC Loss:  17.9112949\n",
      " AUC Loss:  17.9112949\n",
      " AUC Loss:  15.7782507\n",
      " AUC Loss:  15.7782507\n",
      " AUC Loss:  15.7936754\n",
      " AUC Loss:  15.7936754\n",
      " AUC Loss:  14.9965649\n",
      " AUC Loss:  14.9965649\n",
      " AUC Loss:  3.52952695\n",
      " AUC Loss:  3.52952695\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 15.21502\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 14.1120 - acc: 0.7314 - roc_auc_score_loss: 13.6788 - val_loss: 15.6749 - val_acc: 0.6971 - val_roc_auc_score_loss: 14.5996\n",
      "Epoch 10/100\n",
      " AUC Loss:  18.8515491\n",
      " AUC Loss:  18.8515491\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 18.8515 - acc: 0.6641 - roc_auc_score_loss: 18.8515 AUC Loss:  13.3321915\n",
      " AUC Loss:  13.3321915\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 16.0919 - acc: 0.7227 - roc_auc_score_loss: 16.0919 AUC Loss:  16.2668896\n",
      " AUC Loss:  16.2668896\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 16.1502 - acc: 0.7240 - roc_auc_score_loss: 16.1502 AUC Loss:  11.9069252\n",
      " AUC Loss:  11.9069252\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 15.0894 - acc: 0.7285 - roc_auc_score_loss: 15.0894 AUC Loss:  13.9301262\n",
      " AUC Loss:  13.9301262\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 14.8575 - acc: 0.7125 - roc_auc_score_loss: 14.8575 AUC Loss:  15.2618237\n",
      " AUC Loss:  15.2618237\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 14.9249 - acc: 0.7122 - roc_auc_score_loss: 14.9249 AUC Loss:  11.2238808\n",
      " AUC Loss:  11.2238808\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 14.3962 - acc: 0.7266 - roc_auc_score_loss: 14.3962 AUC Loss:  15.0780859\n",
      " AUC Loss:  15.0780859\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 14.4814 - acc: 0.7246 - roc_auc_score_loss: 14.4814 AUC Loss:  13.5138569\n",
      " AUC Loss:  13.5138569\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 14.3739 - acc: 0.7318 - roc_auc_score_loss: 14.3739 AUC Loss:  11.8618555\n",
      " AUC Loss:  11.8618555\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 14.1227 - acc: 0.7383 - roc_auc_score_loss: 14.1227 AUC Loss:  14.2950344\n",
      " AUC Loss:  14.2950344\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 14.1384 - acc: 0.7365 - roc_auc_score_loss: 14.1384 AUC Loss:  11.6036415\n",
      " AUC Loss:  11.6036415\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 13.9272 - acc: 0.7370 - roc_auc_score_loss: 13.9272 AUC Loss:  15.657218\n",
      " AUC Loss:  15.657218\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 14.0602 - acc: 0.7380 - roc_auc_score_loss: 14.0602 AUC Loss:  14.2349901\n",
      " AUC Loss:  14.2349901\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 14.0727 - acc: 0.7321 - roc_auc_score_loss: 14.0727 AUC Loss:  9.45088196\n",
      " AUC Loss:  9.45088196\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 13.7646 - acc: 0.7359 - roc_auc_score_loss: 13.7646 AUC Loss:  13.2021112\n",
      " AUC Loss:  13.2021112\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 13.7294 - acc: 0.7358 - roc_auc_score_loss: 13.7294 AUC Loss:  1.71614659\n",
      " AUC Loss:  1.71614659\n",
      " AUC Loss:  19.4025669\n",
      " AUC Loss:  19.4025669\n",
      " AUC Loss:  18.208477\n",
      " AUC Loss:  18.208477\n",
      " AUC Loss:  14.36483\n",
      " AUC Loss:  14.36483\n",
      " AUC Loss:  16.6313591\n",
      " AUC Loss:  16.6313591\n",
      " AUC Loss:  13.9599218\n",
      " AUC Loss:  13.9599218\n",
      " AUC Loss:  3.19837236\n",
      " AUC Loss:  3.19837236\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 15.21502\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 13.4320 - acc: 0.7381 - roc_auc_score_loss: 13.0228 - val_loss: 15.3721 - val_acc: 0.7429 - val_roc_auc_score_loss: 14.2943\n",
      "Epoch 11/100\n",
      " AUC Loss:  13.2726\n",
      " AUC Loss:  13.2726\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 13.2726 - acc: 0.8125 - roc_auc_score_loss: 13.2726 AUC Loss:  16.6157265\n",
      " AUC Loss:  16.6157265\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 14.9442 - acc: 0.7891 - roc_auc_score_loss: 14.9442 AUC Loss:  12.61903\n",
      " AUC Loss:  12.61903\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 14.1691 - acc: 0.7526 - roc_auc_score_loss: 14.1691 AUC Loss:  10.1397409\n",
      " AUC Loss:  10.1397409\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 13.1618 - acc: 0.7363 - roc_auc_score_loss: 13.1618 AUC Loss:  16.3676147\n",
      " AUC Loss:  16.3676147\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 13.8029 - acc: 0.7078 - roc_auc_score_loss: 13.8029 AUC Loss:  14.6163158\n",
      " AUC Loss:  14.6163158\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 13.9385 - acc: 0.7135 - roc_auc_score_loss: 13.9385 AUC Loss:  12.3395147\n",
      " AUC Loss:  12.3395147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 896/2100 [===========>..................] - ETA: 1s - loss: 13.7101 - acc: 0.7243 - roc_auc_score_loss: 13.7101 AUC Loss:  7.79856539\n",
      " AUC Loss:  7.79856539\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 12.9711 - acc: 0.7266 - roc_auc_score_loss: 12.9711 AUC Loss:  13.3669243\n",
      " AUC Loss:  13.3669243\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 13.0151 - acc: 0.7153 - roc_auc_score_loss: 13.0151 AUC Loss:  14.3361702\n",
      " AUC Loss:  14.3361702\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 13.1472 - acc: 0.7148 - roc_auc_score_loss: 13.1472 AUC Loss:  8.57247925\n",
      " AUC Loss:  8.57247925\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 12.7313 - acc: 0.7195 - roc_auc_score_loss: 12.7313 AUC Loss:  10.7737675\n",
      " AUC Loss:  10.7737675\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 12.5682 - acc: 0.7181 - roc_auc_score_loss: 12.5682 AUC Loss:  12.2998695\n",
      " AUC Loss:  12.2998695\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 12.5476 - acc: 0.7230 - roc_auc_score_loss: 12.5476 AUC Loss:  11.29142\n",
      " AUC Loss:  11.29142\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 12.4578 - acc: 0.7271 - roc_auc_score_loss: 12.4578 AUC Loss:  15.5850582\n",
      " AUC Loss:  15.5850582\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 12.6663 - acc: 0.7276 - roc_auc_score_loss: 12.6663 AUC Loss:  10.7455673\n",
      " AUC Loss:  10.7455673\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 12.5463 - acc: 0.7285 - roc_auc_score_loss: 12.5463 AUC Loss:  2.43689728\n",
      " AUC Loss:  2.43689728\n",
      " AUC Loss:  18.1537361\n",
      " AUC Loss:  18.1537361\n",
      " AUC Loss:  16.969698\n",
      " AUC Loss:  16.969698\n",
      " AUC Loss:  14.4895029\n",
      " AUC Loss:  14.4895029\n",
      " AUC Loss:  14.8899479\n",
      " AUC Loss:  14.8899479\n",
      " AUC Loss:  12.5523529\n",
      " AUC Loss:  12.5523529\n",
      " AUC Loss:  3.12150073\n",
      " AUC Loss:  3.12150073\n",
      "\n",
      "Epoch 00011: val_loss improved from 15.21502 to 14.35766, saving model to /home/valborsf/Documents/UOC/PFMProject/MODELK15/BMODEL/Best_weightsModelK15_1.hdf5\n",
      "2100/2100 [==============================] - 3s 1ms/sample - loss: 12.2959 - acc: 0.7276 - roc_auc_score_loss: 11.9516 - val_loss: 14.3577 - val_acc: 0.7157 - val_roc_auc_score_loss: 13.3628\n",
      "Epoch 12/100\n",
      " AUC Loss:  10.6848888\n",
      " AUC Loss:  10.6848888\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 10.6849 - acc: 0.7109 - roc_auc_score_loss: 10.6849 AUC Loss:  14.5646734\n",
      " AUC Loss:  14.5646734\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 12.6248 - acc: 0.7227 - roc_auc_score_loss: 12.6248 AUC Loss:  10.9779778\n",
      " AUC Loss:  10.9779778\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 12.0758 - acc: 0.7474 - roc_auc_score_loss: 12.0758 AUC Loss:  12.922308\n",
      " AUC Loss:  12.922308\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 12.2875 - acc: 0.7539 - roc_auc_score_loss: 12.2875 AUC Loss:  10.7357712\n",
      " AUC Loss:  10.7357712\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 11.9771 - acc: 0.7625 - roc_auc_score_loss: 11.9771 AUC Loss:  13.6433239\n",
      " AUC Loss:  13.6433239\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 12.2548 - acc: 0.7604 - roc_auc_score_loss: 12.2548 AUC Loss:  10.5169859\n",
      " AUC Loss:  10.5169859\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 12.0066 - acc: 0.7623 - roc_auc_score_loss: 12.0066 AUC Loss:  9.77914715\n",
      " AUC Loss:  9.77914715\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 11.7281 - acc: 0.7744 - roc_auc_score_loss: 11.7281 AUC Loss:  12.4604969\n",
      " AUC Loss:  12.4604969\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 11.8095 - acc: 0.7717 - roc_auc_score_loss: 11.8095 AUC Loss:  11.8935289\n",
      " AUC Loss:  11.8935289\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 11.8179 - acc: 0.7727 - roc_auc_score_loss: 11.8179 AUC Loss:  12.0641403\n",
      " AUC Loss:  12.0641403\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 11.8403 - acc: 0.7713 - roc_auc_score_loss: 11.8403 AUC Loss:  11.3108559\n",
      " AUC Loss:  11.3108559\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 11.7962 - acc: 0.7702 - roc_auc_score_loss: 11.7962 AUC Loss:  14.5999184\n",
      " AUC Loss:  14.5999184\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 12.0118 - acc: 0.7698 - roc_auc_score_loss: 12.0118 AUC Loss:  10.6764793\n",
      " AUC Loss:  10.6764793\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 11.9165 - acc: 0.7718 - roc_auc_score_loss: 11.9165 AUC Loss:  13.4073029\n",
      " AUC Loss:  13.4073029\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 12.0159 - acc: 0.7698 - roc_auc_score_loss: 12.0159 AUC Loss:  9.96960831\n",
      " AUC Loss:  9.96960831\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 11.8880 - acc: 0.7705 - roc_auc_score_loss: 11.8880 AUC Loss:  3.5022192\n",
      " AUC Loss:  3.5022192\n",
      " AUC Loss:  19.2888336\n",
      " AUC Loss:  19.2888336\n",
      " AUC Loss:  17.6903915\n",
      " AUC Loss:  17.6903915\n",
      " AUC Loss:  15.0650702\n",
      " AUC Loss:  15.0650702\n",
      " AUC Loss:  15.6320448\n",
      " AUC Loss:  15.6320448\n",
      " AUC Loss:  12.351799\n",
      " AUC Loss:  12.351799\n",
      " AUC Loss:  3.14605427\n",
      " AUC Loss:  3.14605427\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 14.35766\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 11.6803 - acc: 0.7690 - roc_auc_score_loss: 11.3947 - val_loss: 14.9034 - val_acc: 0.7414 - val_roc_auc_score_loss: 13.8624\n",
      "Epoch 13/100\n",
      " AUC Loss:  12.9615517\n",
      " AUC Loss:  12.9615517\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 12.9616 - acc: 0.7266 - roc_auc_score_loss: 12.9616 AUC Loss:  12.9243069\n",
      " AUC Loss:  12.9243069\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 12.9429 - acc: 0.6992 - roc_auc_score_loss: 12.9429 AUC Loss:  11.5979576\n",
      " AUC Loss:  11.5979576\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 12.4946 - acc: 0.6849 - roc_auc_score_loss: 12.4946 AUC Loss:  17.8771248\n",
      " AUC Loss:  17.8771248\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 13.8402 - acc: 0.6719 - roc_auc_score_loss: 13.8402 AUC Loss:  10.5479221\n",
      " AUC Loss:  10.5479221\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 13.1818 - acc: 0.6703 - roc_auc_score_loss: 13.1818 AUC Loss:  11.6982117\n",
      " AUC Loss:  11.6982117\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 12.9345 - acc: 0.6745 - roc_auc_score_loss: 12.9345 AUC Loss:  10.3128519\n",
      " AUC Loss:  10.3128519\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 12.5600 - acc: 0.6853 - roc_auc_score_loss: 12.5600 AUC Loss:  12.4207\n",
      " AUC Loss:  12.4207\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 12.5426 - acc: 0.6982 - roc_auc_score_loss: 12.5426 AUC Loss:  6.7551136\n",
      " AUC Loss:  6.7551136\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 11.8995 - acc: 0.7179 - roc_auc_score_loss: 11.8995 AUC Loss:  15.1028023\n",
      " AUC Loss:  15.1028023\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 12.2199 - acc: 0.7195 - roc_auc_score_loss: 12.2199 AUC Loss:  10.386241\n",
      " AUC Loss:  10.386241\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 12.0532 - acc: 0.7259 - roc_auc_score_loss: 12.0532 AUC Loss:  9.59808826\n",
      " AUC Loss:  9.59808826\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 11.8486 - acc: 0.7311 - roc_auc_score_loss: 11.8486 AUC Loss:  10.3460941\n",
      " AUC Loss:  10.3460941\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 11.7330 - acc: 0.7374 - roc_auc_score_loss: 11.7330 AUC Loss:  15.0680618\n",
      " AUC Loss:  15.0680618\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 11.9712 - acc: 0.7360 - roc_auc_score_loss: 11.9712 AUC Loss:  13.8398371\n",
      " AUC Loss:  13.8398371\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 12.0958 - acc: 0.7391 - roc_auc_score_loss: 12.0958 AUC Loss:  8.77022457\n",
      " AUC Loss:  8.77022457\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 11.8879 - acc: 0.7471 - roc_auc_score_loss: 11.8879 AUC Loss:  2.29119492\n",
      " AUC Loss:  2.29119492\n",
      " AUC Loss:  19.3471985\n",
      " AUC Loss:  19.3471985\n",
      " AUC Loss:  16.91819\n",
      " AUC Loss:  16.91819\n",
      " AUC Loss:  14.7300777\n",
      " AUC Loss:  14.7300777\n",
      " AUC Loss:  14.8623991\n",
      " AUC Loss:  14.8623991\n",
      " AUC Loss:  12.8813963\n",
      " AUC Loss:  12.8813963\n",
      " AUC Loss:  3.11862731\n",
      " AUC Loss:  3.11862731\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 14.35766\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 11.6503 - acc: 0.7467 - roc_auc_score_loss: 11.3234 - val_loss: 14.6653 - val_acc: 0.7371 - val_roc_auc_score_loss: 13.6430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      " AUC Loss:  10.3042107\n",
      " AUC Loss:  10.3042107\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 10.3042 - acc: 0.7891 - roc_auc_score_loss: 10.3042 AUC Loss:  13.9871597\n",
      " AUC Loss:  13.9871597\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 12.1457 - acc: 0.7617 - roc_auc_score_loss: 12.1457 AUC Loss:  13.9723454\n",
      " AUC Loss:  13.9723454\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 12.7546 - acc: 0.7370 - roc_auc_score_loss: 12.7546 AUC Loss:  14.4826117\n",
      " AUC Loss:  14.4826117\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 13.1866 - acc: 0.7227 - roc_auc_score_loss: 13.1866 AUC Loss:  10.5345993\n",
      " AUC Loss:  10.5345993\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 12.6562 - acc: 0.7250 - roc_auc_score_loss: 12.6562 AUC Loss:  10.9287853\n",
      " AUC Loss:  10.9287853\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 12.3683 - acc: 0.7344 - roc_auc_score_loss: 12.3683 AUC Loss:  13.9562006\n",
      " AUC Loss:  13.9562006\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 12.5951 - acc: 0.7400 - roc_auc_score_loss: 12.5951 AUC Loss:  9.69392109\n",
      " AUC Loss:  9.69392109\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 12.2325 - acc: 0.7441 - roc_auc_score_loss: 12.2325 AUC Loss:  12.0853977\n",
      " AUC Loss:  12.0853977\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 12.2161 - acc: 0.7396 - roc_auc_score_loss: 12.2161 AUC Loss:  8.22241211\n",
      " AUC Loss:  8.22241211\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 11.8168 - acc: 0.7469 - roc_auc_score_loss: 11.8168 AUC Loss:  12.9538593\n",
      " AUC Loss:  12.9538593\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 11.9201 - acc: 0.7358 - roc_auc_score_loss: 11.9201 AUC Loss:  11.7388878\n",
      " AUC Loss:  11.7388878\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 11.9050 - acc: 0.7350 - roc_auc_score_loss: 11.9050 AUC Loss:  9.15654945\n",
      " AUC Loss:  9.15654945\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 11.6936 - acc: 0.7446 - roc_auc_score_loss: 11.6936 AUC Loss:  11.8219376\n",
      " AUC Loss:  11.8219376\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 11.7028 - acc: 0.7455 - roc_auc_score_loss: 11.7028 AUC Loss:  10.2791376\n",
      " AUC Loss:  10.2791376\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 11.6079 - acc: 0.7443 - roc_auc_score_loss: 11.6079 AUC Loss:  10.5477343\n",
      " AUC Loss:  10.5477343\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 11.5416 - acc: 0.7378 - roc_auc_score_loss: 11.5416 AUC Loss:  1.93582368\n",
      " AUC Loss:  1.93582368\n",
      " AUC Loss:  18.0630245\n",
      " AUC Loss:  18.0630245\n",
      " AUC Loss:  17.0912685\n",
      " AUC Loss:  17.0912685\n",
      " AUC Loss:  14.6648617\n",
      " AUC Loss:  14.6648617\n",
      " AUC Loss:  14.0426645\n",
      " AUC Loss:  14.0426645\n",
      " AUC Loss:  12.0927563\n",
      " AUC Loss:  12.0927563\n",
      " AUC Loss:  3.12388277\n",
      " AUC Loss:  3.12388277\n",
      "\n",
      "Epoch 00014: val_loss improved from 14.35766 to 14.15660, saving model to /home/valborsf/Documents/UOC/PFMProject/MODELK15/BMODEL/Best_weightsModelK15_1.hdf5\n",
      "2100/2100 [==============================] - 3s 1ms/sample - loss: 11.3038 - acc: 0.7376 - roc_auc_score_loss: 10.9766 - val_loss: 14.1566 - val_acc: 0.6857 - val_roc_auc_score_loss: 13.1797\n",
      "Epoch 15/100\n",
      " AUC Loss:  9.2898283\n",
      " AUC Loss:  9.2898283\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 9.2898 - acc: 0.7266 - roc_auc_score_loss: 9.2898 AUC Loss:  8.73523521\n",
      " AUC Loss:  8.73523521\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 9.0125 - acc: 0.7109 - roc_auc_score_loss: 9.0125 AUC Loss:  9.07754\n",
      " AUC Loss:  9.07754\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 9.0342 - acc: 0.7604 - roc_auc_score_loss: 9.0342 AUC Loss:  14.0491686\n",
      " AUC Loss:  14.0491686\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 10.2879 - acc: 0.7559 - roc_auc_score_loss: 10.2879 AUC Loss:  9.2653389\n",
      " AUC Loss:  9.2653389\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 10.0834 - acc: 0.7719 - roc_auc_score_loss: 10.0834 AUC Loss:  10.7309618\n",
      " AUC Loss:  10.7309618\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 10.1913 - acc: 0.7773 - roc_auc_score_loss: 10.1913 AUC Loss:  13.8726931\n",
      " AUC Loss:  13.8726931\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 10.7173 - acc: 0.7812 - roc_auc_score_loss: 10.7173 AUC Loss:  13.8966837\n",
      " AUC Loss:  13.8966837\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 11.1147 - acc: 0.7812 - roc_auc_score_loss: 11.1147 AUC Loss:  8.94107914\n",
      " AUC Loss:  8.94107914\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 10.8732 - acc: 0.7873 - roc_auc_score_loss: 10.8732 AUC Loss:  10.5197868\n",
      " AUC Loss:  10.5197868\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 10.8378 - acc: 0.7898 - roc_auc_score_loss: 10.8378 AUC Loss:  10.6023788\n",
      " AUC Loss:  10.6023788\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 10.8164 - acc: 0.7912 - roc_auc_score_loss: 10.8164 AUC Loss:  11.3427973\n",
      " AUC Loss:  11.3427973\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 10.8603 - acc: 0.7904 - roc_auc_score_loss: 10.8603 AUC Loss:  8.19128323\n",
      " AUC Loss:  8.19128323\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 10.6550 - acc: 0.7909 - roc_auc_score_loss: 10.6550 AUC Loss:  11.8610878\n",
      " AUC Loss:  11.8610878\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 10.7411 - acc: 0.7896 - roc_auc_score_loss: 10.7411 AUC Loss:  7.18326855\n",
      " AUC Loss:  7.18326855\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 10.5039 - acc: 0.7880 - roc_auc_score_loss: 10.5039 AUC Loss:  10.8415461\n",
      " AUC Loss:  10.8415461\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 10.5250 - acc: 0.7856 - roc_auc_score_loss: 10.5250 AUC Loss:  2.45060587\n",
      " AUC Loss:  2.45060587\n",
      " AUC Loss:  20.2995834\n",
      " AUC Loss:  20.2995834\n",
      " AUC Loss:  18.8636742\n",
      " AUC Loss:  18.8636742\n",
      " AUC Loss:  15.1201153\n",
      " AUC Loss:  15.1201153\n",
      " AUC Loss:  16.5701981\n",
      " AUC Loss:  16.5701981\n",
      " AUC Loss:  12.6454868\n",
      " AUC Loss:  12.6454868\n",
      " AUC Loss:  3.16917443\n",
      " AUC Loss:  3.16917443\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 14.15660\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 10.3251 - acc: 0.7867 - roc_auc_score_loss: 10.0501 - val_loss: 15.5400 - val_acc: 0.7400 - val_roc_auc_score_loss: 14.4447\n",
      "Epoch 16/100\n",
      " AUC Loss:  8.59359\n",
      " AUC Loss:  8.59359\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 8.5936 - acc: 0.8047 - roc_auc_score_loss: 8.5936 AUC Loss:  13.8899345\n",
      " AUC Loss:  13.8899345\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 11.2418 - acc: 0.7695 - roc_auc_score_loss: 11.2418 AUC Loss:  8.97964096\n",
      " AUC Loss:  8.97964096\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 10.4877 - acc: 0.7760 - roc_auc_score_loss: 10.4877 AUC Loss:  9.96907616\n",
      " AUC Loss:  9.96907616\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 10.3581 - acc: 0.7891 - roc_auc_score_loss: 10.3581 AUC Loss:  12.0273008\n",
      " AUC Loss:  12.0273008\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 10.6919 - acc: 0.7828 - roc_auc_score_loss: 10.6919 AUC Loss:  10.7514343\n",
      " AUC Loss:  10.7514343\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 10.7018 - acc: 0.7891 - roc_auc_score_loss: 10.7018 AUC Loss:  9.10472298\n",
      " AUC Loss:  9.10472298\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 10.4737 - acc: 0.7958 - roc_auc_score_loss: 10.4737 AUC Loss:  8.3403511\n",
      " AUC Loss:  8.3403511\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 10.2070 - acc: 0.8027 - roc_auc_score_loss: 10.2070 AUC Loss:  9.34094906\n",
      " AUC Loss:  9.34094906\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 10.1108 - acc: 0.7986 - roc_auc_score_loss: 10.1108 AUC Loss:  9.39736843\n",
      " AUC Loss:  9.39736843\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 10.0394 - acc: 0.7961 - roc_auc_score_loss: 10.0394 AUC Loss:  10.0237932\n",
      " AUC Loss:  10.0237932\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 10.0380 - acc: 0.7884 - roc_auc_score_loss: 10.0380 AUC Loss:  10.716342\n",
      " AUC Loss:  10.716342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536/2100 [====================>.........] - ETA: 0s - loss: 10.0945 - acc: 0.7865 - roc_auc_score_loss: 10.0945 AUC Loss:  7.1618557\n",
      " AUC Loss:  7.1618557\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 9.8690 - acc: 0.7861 - roc_auc_score_loss: 9.8690   AUC Loss:  9.58783627\n",
      " AUC Loss:  9.58783627\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 9.8489 - acc: 0.7852 - roc_auc_score_loss: 9.8489 AUC Loss:  7.29113102\n",
      " AUC Loss:  7.29113102\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 9.6784 - acc: 0.7859 - roc_auc_score_loss: 9.6784 AUC Loss:  8.23914\n",
      " AUC Loss:  8.23914\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 9.5884 - acc: 0.7876 - roc_auc_score_loss: 9.5884 AUC Loss:  2.34739542\n",
      " AUC Loss:  2.34739542\n",
      " AUC Loss:  20.0226555\n",
      " AUC Loss:  20.0226555\n",
      " AUC Loss:  18.7450466\n",
      " AUC Loss:  18.7450466\n",
      " AUC Loss:  14.9616108\n",
      " AUC Loss:  14.9616108\n",
      " AUC Loss:  14.8589134\n",
      " AUC Loss:  14.8589134\n",
      " AUC Loss:  12.673008\n",
      " AUC Loss:  12.673008\n",
      " AUC Loss:  3.40980911\n",
      " AUC Loss:  3.40980911\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 14.15660\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 9.4091 - acc: 0.7876 - roc_auc_score_loss: 9.1625 - val_loss: 15.1515 - val_acc: 0.7557 - val_roc_auc_score_loss: 14.1118\n",
      "Epoch 17/100\n",
      " AUC Loss:  6.91187525\n",
      " AUC Loss:  6.91187525\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 6.9119 - acc: 0.7969 - roc_auc_score_loss: 6.9119 AUC Loss:  12.1493702\n",
      " AUC Loss:  12.1493702\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 9.5306 - acc: 0.7656 - roc_auc_score_loss: 9.5306 AUC Loss:  8.25242233\n",
      " AUC Loss:  8.25242233\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 9.1046 - acc: 0.7578 - roc_auc_score_loss: 9.1046 AUC Loss:  12.0625105\n",
      " AUC Loss:  12.0625105\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 9.8440 - acc: 0.7559 - roc_auc_score_loss: 9.8440 AUC Loss:  8.79067612\n",
      " AUC Loss:  8.79067612\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 9.6334 - acc: 0.7672 - roc_auc_score_loss: 9.6334 AUC Loss:  8.54601383\n",
      " AUC Loss:  8.54601383\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 9.4521 - acc: 0.7786 - roc_auc_score_loss: 9.4521 AUC Loss:  11.919878\n",
      " AUC Loss:  11.919878\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 9.8047 - acc: 0.7812 - roc_auc_score_loss: 9.8047 AUC Loss:  10.9962168\n",
      " AUC Loss:  10.9962168\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 9.9536 - acc: 0.7832 - roc_auc_score_loss: 9.9536 AUC Loss:  10.7748489\n",
      " AUC Loss:  10.7748489\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 10.0449 - acc: 0.7899 - roc_auc_score_loss: 10.0449 AUC Loss:  8.86388111\n",
      " AUC Loss:  8.86388111\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 9.9268 - acc: 0.7969 - roc_auc_score_loss: 9.9268   AUC Loss:  9.62176609\n",
      " AUC Loss:  9.62176609\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 9.8990 - acc: 0.7990 - roc_auc_score_loss: 9.8990 AUC Loss:  6.82010317\n",
      " AUC Loss:  6.82010317\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 9.6425 - acc: 0.8027 - roc_auc_score_loss: 9.6425 AUC Loss:  7.31064272\n",
      " AUC Loss:  7.31064272\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 9.4631 - acc: 0.8053 - roc_auc_score_loss: 9.4631 AUC Loss:  9.62914\n",
      " AUC Loss:  9.62914\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 9.4750 - acc: 0.8047 - roc_auc_score_loss: 9.4750 AUC Loss:  9.17965698\n",
      " AUC Loss:  9.17965698\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 9.4553 - acc: 0.8042 - roc_auc_score_loss: 9.4553 AUC Loss:  10.8200569\n",
      " AUC Loss:  10.8200569\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 9.5406 - acc: 0.8027 - roc_auc_score_loss: 9.5406 AUC Loss:  1.64472425\n",
      " AUC Loss:  1.64472425\n",
      " AUC Loss:  19.5642452\n",
      " AUC Loss:  19.5642452\n",
      " AUC Loss:  18.4850712\n",
      " AUC Loss:  18.4850712\n",
      " AUC Loss:  16.6800537\n",
      " AUC Loss:  16.6800537\n",
      " AUC Loss:  14.3722153\n",
      " AUC Loss:  14.3722153\n",
      " AUC Loss:  11.5547838\n",
      " AUC Loss:  11.5547838\n",
      " AUC Loss:  3.4184556\n",
      " AUC Loss:  3.4184556\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 14.15660\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 9.3451 - acc: 0.8014 - roc_auc_score_loss: 9.0761 - val_loss: 15.0416 - val_acc: 0.6829 - val_roc_auc_score_loss: 14.0125\n",
      "Epoch 18/100\n",
      " AUC Loss:  8.55952644\n",
      " AUC Loss:  8.55952644\n",
      " 128/2100 [>.............................] - ETA: 1s - loss: 8.5595 - acc: 0.6797 - roc_auc_score_loss: 8.5595 AUC Loss:  8.08003807\n",
      " AUC Loss:  8.08003807\n",
      " 256/2100 [==>...........................] - ETA: 1s - loss: 8.3198 - acc: 0.6914 - roc_auc_score_loss: 8.3198 AUC Loss:  9.36370373\n",
      " AUC Loss:  9.36370373\n",
      " 384/2100 [====>.........................] - ETA: 1s - loss: 8.6678 - acc: 0.6615 - roc_auc_score_loss: 8.6678 AUC Loss:  8.59940815\n",
      " AUC Loss:  8.59940815\n",
      " 512/2100 [======>.......................] - ETA: 1s - loss: 8.6507 - acc: 0.6836 - roc_auc_score_loss: 8.6507 AUC Loss:  8.37586594\n",
      " AUC Loss:  8.37586594\n",
      " 640/2100 [========>.....................] - ETA: 1s - loss: 8.5957 - acc: 0.6969 - roc_auc_score_loss: 8.5957 AUC Loss:  7.75437832\n",
      " AUC Loss:  7.75437832\n",
      " 768/2100 [=========>....................] - ETA: 1s - loss: 8.4555 - acc: 0.7161 - roc_auc_score_loss: 8.4555 AUC Loss:  5.45625925\n",
      " AUC Loss:  5.45625925\n",
      " 896/2100 [===========>..................] - ETA: 1s - loss: 8.0270 - acc: 0.7400 - roc_auc_score_loss: 8.0270 AUC Loss:  11.2013912\n",
      " AUC Loss:  11.2013912\n",
      "1024/2100 [=============>................] - ETA: 1s - loss: 8.4238 - acc: 0.7373 - roc_auc_score_loss: 8.4238 AUC Loss:  8.10129356\n",
      " AUC Loss:  8.10129356\n",
      "1152/2100 [===============>..............] - ETA: 0s - loss: 8.3880 - acc: 0.7344 - roc_auc_score_loss: 8.3880 AUC Loss:  13.5967\n",
      " AUC Loss:  13.5967\n",
      "1280/2100 [=================>............] - ETA: 0s - loss: 8.9089 - acc: 0.7289 - roc_auc_score_loss: 8.9089 AUC Loss:  9.5594759\n",
      " AUC Loss:  9.5594759\n",
      "1408/2100 [===================>..........] - ETA: 0s - loss: 8.9680 - acc: 0.7322 - roc_auc_score_loss: 8.9680 AUC Loss:  9.60294056\n",
      " AUC Loss:  9.60294056\n",
      "1536/2100 [====================>.........] - ETA: 0s - loss: 9.0209 - acc: 0.7337 - roc_auc_score_loss: 9.0209 AUC Loss:  11.7591419\n",
      " AUC Loss:  11.7591419\n",
      "1664/2100 [======================>.......] - ETA: 0s - loss: 9.2315 - acc: 0.7380 - roc_auc_score_loss: 9.2315 AUC Loss:  10.4648829\n",
      " AUC Loss:  10.4648829\n",
      "1792/2100 [========================>.....] - ETA: 0s - loss: 9.3196 - acc: 0.7422 - roc_auc_score_loss: 9.3196 AUC Loss:  10.6833143\n",
      " AUC Loss:  10.6833143\n",
      "1920/2100 [==========================>...] - ETA: 0s - loss: 9.4106 - acc: 0.7479 - roc_auc_score_loss: 9.4106 AUC Loss:  8.46172142\n",
      " AUC Loss:  8.46172142\n",
      "2048/2100 [============================>.] - ETA: 0s - loss: 9.3513 - acc: 0.7515 - roc_auc_score_loss: 9.3513 AUC Loss:  1.51288235\n",
      " AUC Loss:  1.51288235\n",
      " AUC Loss:  18.8320847\n",
      " AUC Loss:  18.8320847\n",
      " AUC Loss:  17.633213\n",
      " AUC Loss:  17.633213\n",
      " AUC Loss:  15.0562258\n",
      " AUC Loss:  15.0562258\n",
      " AUC Loss:  13.8972092\n",
      " AUC Loss:  13.8972092\n",
      " AUC Loss:  12.3771591\n",
      " AUC Loss:  12.3771591\n",
      " AUC Loss:  3.30826759\n",
      " AUC Loss:  3.30826759\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 14.15660\n",
      "2100/2100 [==============================] - 2s 1ms/sample - loss: 9.1572 - acc: 0.7524 - roc_auc_score_loss: 8.8902 - val_loss: 14.5091 - val_acc: 0.7157 - val_roc_auc_score_loss: 13.5174\n",
      "Epoch 00018: early stopping\n",
      "Time spent in training :00:00:48\n"
     ]
    }
   ],
   "source": [
    "# Model fit\n",
    "epochs= 100\n",
    "batch_size = 128\n",
    "import time\n",
    "start_time = time.time()\n",
    "history = model.fit (\n",
    "           train_image_tensor, \n",
    "           train_label_tensor, \n",
    "#           slice_10_pictures, \n",
    "#           slice_10_labels, \n",
    "           epochs = epochs, \n",
    "           batch_size = batch_size, \n",
    "           callbacks=callbacks_list,\n",
    "           validation_data =( val_image_tensor,val_label_tensor))\n",
    "#           validation_data =( val_10_pictures ,val_10_labels))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print( time.strftime('Time spent in training :'\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "save_model(model, history, model_bin_dir, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Test if not need to Train \n",
    "if not TRAIN :\n",
    "    model = model_load ( model_bin_dir, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3hU1fXw8e8CApGL3BEEIaC+VsAAIQIKAqIiIIhaK2AUvBX1p623VihYtSqKYhFRq6KCF1LQaqk3EFGxSFUwQa4CBRQkkkJELkFQCVnvH/tMGMLMZJKZzCST9Xme88zMua45M7POnn322UdUFWOMMYmrWrwDMMYYU74s0RtjTIKzRG+MMQnOEr0xxiQ4S/TGGJPgLNEbY0yCs0RfQYlIdRHZJyKtozlvPInISSIS9fa8InKuiGz2e71eRM4KZ94ybOt5ERlX1uVDrPcBEXkx2uuNpdK8BxFZLCJXlW9ExscSfZR4idY3FIrIAb/XGaVdn6oeUtW6qvptNOetClT1FFX9JNL1iMh1IvJxsXVfp6oPRrruePIOdioirxUbn+6N/yDG8Ryxn0WkgYh8LiKviUiSiJwjIh+LyF4R2Rhg+Zxiv7d5YWyzk4i8LyI7RaQgym+pwrFEHyVeoq2rqnWBb4EhfuMyi88vIjViH6UxRbYDfUSkgd+4kcB/4xQPACLSGPgQ2ACMUNWDwI/A88CYEIsO9Pu9DQxjU78As4HfRhpzZWCJPka8v7WvisgsEckHrhCRM7ySy24RyRWRqSKS5M1fwytdpXivZ3rT54lIvoh8JiJtSzuvN32giPxXRPaIyBMi8p9gf6PDjPF6EdkoIrtEZKrfstVF5DGv1LQJGBBi/9wlIrOLjXtKRCZ7z68TkbXe+9kkIteFWFeOiPT1ntcWkVe82NYAXQNs92tvvWtE5EJv/GnAk8BZXinxe799e6/f8jd4732niPxLRFqEs29KIiIXefHsFpGPROQUv2njRGSbV8Jd5/dee4jIMm/8dhGZFGITPwFvA8N88QKXAn8vFkcvEcnyvitLRaS737R2IvKJt+/mA42LLdvT77uzXER6l/CemwELgS+BUap6CEBVP1fVmcA3Jey2sKnqWlWdDnwVrXVWaKpqQ5QHYDNwbrFxD+BKEUNwB9hjgNOB7kANoB2uNHWzN38NQIEU7/VM4HsgHUgCXgVmlmHeZkA+MNSbdjtwELgqyHsJJ8Y3gfpACvCD770DNwNrgFa4JLDIfeUCbqcdsA+o47fuHUC693qIN48A/YADQKo37Vxgs9+6coC+3vNHgY+BhkAb3A/bf97LgBbeZ3K5F8Nx3rTrgI+LxTkTuNd73t+LsTOQDPwN+CicfRPg/T8AvOg9P9WLo5/3GY3z9nsS0AHYAjT35m0LtPOef4ErBQPUA7oH2da5uO9ob+A/3rgLgXeBG4APvHFNgD3ACO/9XAHsBBp605cCk4BawNlezL73cII37/nevh2A+0429qYvxvvOeft5NbAWd3CVIHEPADYGGJ8D/M/7LOYDp5Xit/oroCDeOaO8ByvRx9ZiVX1bVQtV9YCqfqGqS1S1QFW/BqYBfUIs/7qqZqn7O5uJSzClnXcwsFxV3/SmPYb7AQYUZowPqeoeVd2MS6q+bV0GPKaqOaq6E5gYYjtf437sQ71R5wG7VTXLm/62qn6tzke4v/cBT7gWcxnwgKruUtUtuETiv93XVDXX+0z+jkuA6WGsFyADeF5Vl6vqT8BYXHVIK795gu2bUIYDb6nqR95nNBE4FnfALcAdVDqISA1V/cbbd+AO2CeLSGNVzVfVJSVs5xOghYiciKu2ebnY9CHAGlWd5X3+M4GvgQtEpJ33Xu5R1Z9VdSEw12/Zkd57mO/t2/eAFQT/V9cGOBF3oCjtCfvhuANpW9wBZL6I1C/lOhKaJfrY2ur/QkR+JSLvisj/RGQvcB+uFBXM//ye7wfqlmHe4/3j8H5UOcFWEmaMYW0LVxIN5e+40iO40nXRuQ0RGSwiS0TkBxHZjStNh9pXPi1CxSAiV4nICq96YTeuhBfOesG9v6L1qepeYBfQ0m+e0nxmwdZbiPuMWqrqeuAO3OewQ1xVYHNv1quB9sB6r5plUKiNeJ/9TOAW3EHzzVBxeLbg3t/xwE5V3V9smk8bYIRvv3r7toe3XCDZuAPlfBHpFCruAO9jsar+pKo/qur9uP18ZmnWkegs0cdW8ZLKs7hS7EmqeixwN65qojzl4qpSABAR4cjEVFwkMebi/sL7lNT881XgXK9EPBSvvlhEjgFeBx7CVas0AN4PM47/BYvBK5U+DdyIq1JoAKzzW29JJcttuITmW189XBXRd2HEVZr1VsN9Zt8BqOpMVe2JK8FWx+0XVHW9qg7HVc/9FXhDRJJL2NbLwE240vdPoeLwtPbiyAUae5+N/zSfrcAMVW3gN9RR1aDnDVR1shf3AhE5tYS4Q1HK/3dUqViij696uDrQH70v9vUx2OY7QJqIDPFOwN0CNC2nGF8DbhWRluJaU4RqNYGqbsf99Z4BrFfVDd6kWkBNIA84JCKDgXNKEcM4cU32WuPOG/jUxSWFPNwx7zpcid5nO9BKvJPPAcwCrhWRVBGphUu4n6hq0H9IpYj5QhHp6237j7jzKktE5FQROdvb3gFvOIR7A1eKSBPvH8Ae770VhtqQqm4E+uIO4MW9g6siGuadXL4cOAmYq6qbgJXAvSJS0zvReoHfsq8AF4vIeeJOyid7cQcr0fvieRB38P1QRE723lc174CV5F5KshxuEJAiImeKa4aZLCJjcdVcn4XajjjJuO8V3rI1Qy1TmVmij687gFG4H/GzuBJtufKS6TBgMu5k2Ym4Vg4/l0OMT+Pq0lfhThS+HsYyf8edLCxq/aGqu4HbgDm4E5qX4pJQOO7BlT43A/Pwq4dW1ZXAVNxJxVxckvev116Aa+a3XUT8q2B8y7+Hq0KZ4y3fGldvHxFVXYPb50/jDkIDgAu9+vpawCO48yr/w/2DuMtbdBCwVlyrrkeBYar6Sxjb+0RVcwOMz8OdpB2D+67cBgxW1R+8WYYDPXGfyXhccvctuxm4GPiz9x6+xX2XSsw5qnoP7nP6UFxrMd/J97dwJ+QP4D5LcAWRZ3FVZt/hCgADVXVXCZs50VvPCty/ogMkcAscKf15D5NIRKQ67i/6pRqFi4yMMRWPleirIBEZICL1vb//f8a15Fga57CMMeXEEn3V1AvXTO57XLXARaoarOrGmEpJXBcH+wIMd8Y7tlizqhtjjElwVqI3xpgEVyE71mrSpImmpKTEOwxjjKk0srOzv1fVgE2lK2SiT0lJISsrK95hGGNMpSEiQa88t6obY4xJcJbojTEmwVmiN8aYBFch6+iNMbF18OBBcnJy+Omn4v2amYomOTmZVq1akZQUrAumo1miN8aQk5NDvXr1SElJwXVoaioiVWXnzp3k5OTQtm3bkhfwJEzVTWYmpKRAtWruMfOou7QaY4L56aefaNy4sSX5Ck5EaNy4can/eSVEiT4zE0aPhv3eLRC2bHGvATIi7kvQmKrBknzlUJbPKSFK9OPHH07yPvv3u/HGGFPVJUSi//bb0o03xlQcO3fupHPnznTu3JnmzZvTsmXLote//FJid/oAXH311axfvz7kPE899RSZUarT7dWrF8uXL4/KumIhIapuWrd21TWBxhtjoi8z0/1j/vZb9zubMKHs1aSNGzcuSpr33nsvdevW5Q9/+MMR86gqqkq1aoHLpjNmzChxOzfddFPZAkwACVGinzABatc+clzt2m68MSa6fOfEtmwB1cPnxKLdAGLjxo107NiRG264gbS0NHJzcxk9ejTp6el06NCB++67r2heXwm7oKCABg0aMHbsWDp16sQZZ5zBjh07ALjrrruYMmVK0fxjx46lW7dunHLKKXz66acA/Pjjj/z617+mU6dOjBgxgvT09BJL7jNnzuS0006jY8eOjBs3DoCCggKuvPLKovFTp04F4LHHHqN9+/Z06tSJK664Iro7LISESPQZGTBtGrRpAyLucdo0OxFrTHmI5Tmxr776imuvvZYvv/ySli1bMnHiRLKyslixYgULFizgq6+Ovvvfnj176NOnDytWrOCMM85g+vTpAdetqixdupRJkyYVHTSeeOIJmjdvzooVKxg7dixffvllyPhycnK46667WLhwIV9++SX/+c9/eOedd8jOzub7779n1apVrF69mpEjRwLwyCOPsHz5clasWMGTTz4Z4d4JX0IkenBJffNmKCx0j5bkjSkfsTwnduKJJ3L66acXvZ41axZpaWmkpaWxdu3agIn+mGOOYeDAgQB07dqVzZs3B1z3JZdcctQ8ixcvZvjw4QB06tSJDh06hIxvyZIl9OvXjyZNmpCUlMTll1/OokWLOOmkk1i/fj233HIL8+fPp379+gB06NCBK664gszMzFJd8BSphEn0xpjYCHbuqzzOidWpU6fo+YYNG3j88cf56KOPWLlyJQMGDAjYnrxmzZpFz6tXr05BQUHAddeqVeuoeUp7I6Zg8zdu3JiVK1fSq1cvpk6dyvXXXw/A/PnzueGGG1i6dCnp6ekcOnSoVNsrK0v0xphSidc5sb1791KvXj2OPfZYcnNzmT9/ftS30atXL1577TUAVq1aFfAfg78ePXqwcOFCdu7cSUFBAbNnz6ZPnz7k5eWhqvzmN7/hL3/5C8uWLePQoUPk5OTQr18/Jk2aRF5eHvuL14GVk4RodWOMiR1ftWi0Wt2EKy0tjfbt29OxY0fatWtHz549o76N3/3ud4wcOZLU1FTS0tLo2LFjUbVLIK1ateK+++6jb9++qCpDhgzhggsuYNmyZVx77bWoKiLCww8/TEFBAZdffjn5+fkUFhYyZswY6tWrF/X3EEiFvGdsenq62o1HjImdtWvXcuqpp8Y7jLgrKCigoKCA5ORkNmzYQP/+/dmwYQM1alSsMnGgz0tEslU1PdD8FSt6Y4yJo3379nHOOedQUFCAqvLss89WuCRfFpX/HRhjTJQ0aNCA7OzseIcRdSUmehE5AXgZaA4UAtNU9XEReRU4xZutAbBbVTsHWH4zkA8cAgqC/bUwxhhTPsIp0RcAd6jqMhGpB2SLyAJVHeabQUT+CuwJsY6zVfX7CGM1xhhTBiUmelXNBXK95/kishZoCXwFIK7PzMuAfuUYpzHGmDIqVTt6EUkBugBL/EafBWxX1Q1BFlPgfRHJFpHRIdY9WkSyRCQrLy+vNGEZY4wJIexELyJ1gTeAW1V1r9+kEcCsEIv2VNU0YCBwk4j0DjSTqk5T1XRVTW/atGm4YRljEkDfvn2PugBqypQp/N///V/I5erWrQvAtm3buPTSS4Ouu6Tm2lOmTDni4qVBgwaxe/fucEIP6d577+XRRx+NeD2RCivRi0gSLslnquo//cbXAC4BXg22rKpu8x53AHOAbpEEbIxJPCNGjGD27NlHjJs9ezYjRowIa/njjz+e119/vczbL57o586dS4MGDcq8voqmxETv1cG/AKxV1cnFJp8LrFPVnCDL1vFO4CIidYD+wOrIQjbGJJpLL72Ud955h59//hmAzZs3s23bNnr16lXUtj0tLY3TTjuNN99886jlN2/eTMeOHQE4cOAAw4cPJzU1lWHDhnHgwIGi+W688caibo7vueceAKZOncq2bds4++yzOfvsswFISUnh++9d+5HJkyfTsWNHOnbsWNTN8ebNmzn11FP57W9/S4cOHejfv/8R2wlk+fLl9OjRg9TUVC6++GJ27dpVtP327duTmppa1KHav//976Kbr3Tp0oX8/Pwy71sIr9VNT+BKYJWI+DpmHqeqc4HhFKu2EZHjgedVdRBwHDDHu8dhDeDvqvpeRBEbY8rVrbdCtG+e1LkzeDkyoMaNG9OtWzfee+89hg4dyuzZsxk2bBgiQnJyMnPmzOHYY4/l+++/p0ePHlx44YVB75369NNPU7t2bVauXMnKlStJS0srmjZhwgQaNWrEoUOHOOecc1i5ciW///3vmTx5MgsXLqRJkyZHrCs7O5sZM2awZMkSVJXu3bvTp08fGjZsyIYNG5g1axbPPfccl112GW+88UbIPuZHjhzJE088QZ8+fbj77rv5y1/+wpQpU5g4cSLffPMNtWrVKqouevTRR3nqqafo2bMn+/btIzk5uRR7+2glluhVdbGqiqqmqmpnb5jrTbtKVZ8pNv82L8mjql+raidv6KCqdisQY0xA/tU3/tU2qsq4ceNITU3l3HPP5bvvvmP79u1B17No0aKihJuamkpqamrRtNdee420tDS6dOnCmjVrSuy0bPHixVx88cXUqVOHunXrcskll/DJJ58A0LZtWzp3dpcOheoOGVwf+bt376ZPnz4AjBo1ikWLFhXFmJGRwcyZM4uuwu3Zsye33347U6dOZffu3RFfnWtXxhpjjhCq5F2eLrroIm6//XaWLVvGgQMHikrimZmZ5OXlkZ2dTVJSEikpKQG7J/YXqLT/zTff8Oijj/LFF1/QsGFDrrrqqhLXE6ovMF83x+C6Oi6p6iaYd999l0WLFvHWW29x//33s2bNGsaOHcsFF1zA3Llz6dGjBx988AG/+tWvyrR+sG6KjTEVRN26denbty/XXHPNESdh9+zZQ7NmzUhKSmLhwoVsCXSDaD+9e/cuugn46tWrWblyJeC6Oa5Tpw7169dn+/btzJs3r2iZevXqBawH7927N//617/Yv38/P/74I3PmzOGss84q9XurX78+DRs2LPo38Morr9CnTx8KCwvZunUrZ599No888gi7d+9m3759bNq0idNOO40xY8aQnp7OunXrSr1Nf1aiN8ZUGCNGjOCSSy45ogVORkYGQ4YMIT09nc6dO5dYsr3xxhu5+uqrSU1NpXPnznTr5hr6derUiS5dutChQ4ejujkePXo0AwcOpEWLFixcuLBofFpaGldddVXROq677jq6dOkSspommJdeeokbbriB/fv3065dO2bMmMGhQ4e44oor2LNnD6rKbbfdRoMGDfjzn//MwoULqV69Ou3bty+6Y1ZZWTfFxhjrpriSKW03xVZ1Y4wxCc4SvTHGJDhL9MYYoPQ3xjbxUZbPyRK9MYbk5GR27txpyb6CU1V27txZ6guorNWNMYZWrVqRk5OD9Rxb8SUnJ9OqVatSLWOJ3hhDUlISbdu2jXcYppxY1Y0xxiQ4S/TGGJPgLNEbY0yCs0RvjDEJzhK9McYkOEv0xhiT4MK5leAJIrJQRNaKyBoRucUbf6+IfCciy71hUJDlB4jIehHZKCJjo/0GjDHGhBZOO/oC4A5VXebd/zVbRBZ40x5T1aC3OBeR6sBTwHlADvCFiLylqqFv62KMMSZqwrmVYK6qLvOe5wNrgZZhrr8bsNG7peAvwGxgaFmDNcYYU3qlqqMXkRSgC7DEG3WziKwUkeki0jDAIi2BrX6vcwhykBCR0SKSJSJZdhm2McZET9iJXkTqAm8At6rqXuBp4ESgM5AL/DXQYgHGBew1SVWnqWq6qqY3bdo03LCMMcaUIKxELyJJuCSfqar/BFDV7ap6SFULgedw1TTF5QAn+L1uBWyLLGRjjDGlEU6rGwFeANaq6mS/8S38ZrsYWB1g8S+Ak0WkrYjUBIYDb0UWsjHGmNIIp9VNT+BKYJWILPfGjQNGiEhnXFXMZuB6ABE5HnheVQepaoGI3AzMB6oD01V1TZTfgzHGmBBKTPSqupjAde1zg8y/DRjk93pusHmNMcaUP7sy1hhjEpwlemOMSXCW6I0xJsFZojfGmARnid4YYxKcJXpjjElwluiNMSbBWaIvJjMTUlKgWjX3mJkZ74iMMSYy4VwZW2VkZsLo0bB/v3u9ZYt7DZCREb+4jDEmElai9zN+/OEk77N/vxtvjDGVlSV6P99+W7rxxhhTGVii99O6denGG2NMZWCJ3s+ECVC79pHjatd2440xprKyRO8nIwOmTYM2bUDEPU6bZidijTGVm7W6KSYjwxK7MSaxWIneGGMSXDi3EjxBRBaKyFoRWSMit3jjJ4nIOhFZKSJzRKRBkOU3i8gqEVkuIlnRfgP+1q2DbXZHWmOMOUI4JfoC4A5VPRXoAdwkIu2BBUBHVU0F/gv8KcQ6zlbVzqqaHnHEQezeDV27wl13ldcWjDGmciox0atqrqou857nA2uBlqr6vqoWeLN9DrQqvzBL1qAB3HgjvPgirFoVz0iMMaZiKVUdvYikAF2AJcUmXQPMC7KYAu+LSLaIjA6x7tEikiUiWXl5eaUJq8i4cVC/PowZU6bFjTEmIYWd6EWkLvAGcKuq7vUbPx5XvROs+6+eqpoGDMRV+/QONJOqTlPVdFVNb9q0adhvwF+jRq67gnnz4KOPyrQKY4xJOGElehFJwiX5TFX9p9/4UcBgIENVNdCyqrrNe9wBzAG6RRp0KDff7K5kvfNOKCwszy0ZY0zlEE6rGwFeANaq6mS/8QOAMcCFqro/yLJ1RKSe7znQH1gdjcCDSU6GBx6A7Gx49dXy3JIxxlQO4ZToewJXAv28JpLLRWQQ8CRQD1jgjXsGQESOF5G53rLHAYtFZAWwFHhXVd+L/ts4UkYGdOrk6ux//rm8t2aMMRVbiVfGqupiQAJMmhtgnK+qZpD3/GugUyQBlkW1ajBpEvTvD3/7G9x2W6wjMMaYiiNhr4w97zyX6B94wLWxN8aYqiphEz3Aww/Drl0wcWK8IzHGmPhJ6ETfuTNccQVMmWI3DzHGVF0JnegB7r/fPd59d3zjMMaYeEn4RN+mDfz+9/Dyy7BiRbyjMcaY2Ev4RA/wpz+5vnDGjo13JMYYE3tVItE3bOh6tXzvPfjgg3hHY4wxsVUlEj3ATTe5ahzrGsEYU9VUmURfq5a7yfeXX8KsWfGOxhhjYqfKJHqAESOgSxfXw+VPP8U7GmOMiY0qleh9XSNs2eK6RjDGmKqgSiV6gHPOgQEDXNcIu3bFOxpjjCl/VS7Rg+saYfdueOiheEdijDHlr0om+tRUGDkSpk511TjGGJPIqmSih8NdI/z5z/GNwxhjyluVTfQnnAC33gozZ8Ly5dFff2YmpKS4E8ApKe61McbEQzi3EjxBRBaKyFoRWSMit3jjG4nIAhHZ4D02DLL8KG+eDd49ZiuMsWPdVbNjxkR3vZmZMHq0qxZSdY+jR1uyN8bERzgl+gLgDlU9FegB3CQi7YGxwIeqejLwoff6CCLSCLgH6I67Kfg9wQ4I8dCggau6ef99N0TL+PGwv9hddPfvd+ONMSbWSkz0qpqrqsu85/nAWqAlMBR4yZvtJeCiAIufDyxQ1R9UdRewABgQjcCj5cYbXdVKNLtGCNb3vfWJb4yJh1LV0YtICtAFWAIcp6q54A4GQLMAi7QEtvq9zvHGBVr3aBHJEpGsvLy80oQVkVq14MEHXRfG0apaad26dOONMaY8hZ3oRaQu8AZwq6ruDXexAOM00IyqOk1V01U1vWnTpuGGFRXDhkHXrq6Hy2h0jTBhAtSufeS42rXdeGOMibWwEr2IJOGSfKaq/tMbvV1EWnjTWwA7AiyaA5zg97oVsK3s4ZYPX9cI334LTz4Z+foyMmDaNNdbpoh7nDbNjTfGmFgT1YAF7MMziAiuDv4HVb3Vb/wkYKeqThSRsUAjVb2z2LKNgGwgzRu1DOiqqj+E2mZ6erpmZWWV+s1E6oIL4NNPYdMmaNQo5ps3xpgyE5FsVU0PNC2cEn1P4Eqgn4gs94ZBwETgPBHZAJznvUZE0kXkeQAvod8PfOEN95WU5ONp4kTYs8fV2RtjTKIosUQfD/Eq0QNcc407KbtuHbRtG5cQjDGm1CIt0Vcp990HNWvCuefCxo3xjsYYYyJnib6YVq3cfWX37IEzz4Q4/bEwxpiosUQfQPfu7qRsnTrQty/Mnx/viIwxpuws0Qfx//6fS/YnnQSDB8Mrr8Q7ImOMKRtL9CG0aAH//jf07u36r580yXVSZowxlYkl+hLUrw9z57qrZ++8E26/PXp94hhjTCzUiHcAlUGtWvD3v0Pz5jBlCuTmwksvufHGGFPRWaIPU7Vq8Nhj0LKlK9nn5cGcOXDssfGOzBhjQrOqm1IQgT/+EV5+GRYtcnX3ubnxjsoYY0KzRF8GV14J77zjLqg680xYvz7eERljTHCW6Mvo/PPh44/hxx+hZ09YsiTeERljTGCW6COQnu7a2tevD/36wbvvRn8bdpNxY0ykLNFH6KSTXLL/1a9g6FCYMSN667abjBtjosESfRQcd5yrxunXz/V++eCD0bmwym4yboyJBkv0UVKvnjtBm5HhEvHvfgeHDkW2TrvJuDEmGqwdfRTVrOmaXrZoAY8+Ctu2waWXwsGDwYdffgk+7Zhjji7Rg91k3BhTOiUmehGZDgwGdqhqR2/cq8Ap3iwNgN2q2jnAspuBfOAQUBCsU/xE4rv/7PHHu+4S5swJPb8IJCUFHurVgwMHjqwGspuMG2NKK5wS/YvAk8DLvhGqOsz3XET+CuwJsfzZqvp9WQOsrG67zfWPk59/OHHXrHl0Mq9ePfR6MjPhlltg5053Fe7f/mY3GTfGlE6JiV5VF4lISqBp3o3DLwP6RTesxHD88ZGvIyPDDaNHw3PP2U3LjTGlF+nJ2LOA7aq6Ich0Bd4XkWwRGR1qRSIyWkSyRCQrLy8vwrASz+OPQ6dO7qrcrVvjHY0xpjKJNNGPAGaFmN5TVdOAgcBNItI72IyqOk1V01U1vWnTphGGlXiOOQZeew1+/tlVCR08GO+IjDGVRZkTvYjUAC4BXg02j6pu8x53AHOAbmXdnnF3vXr+efjsMxg3Lt7RGGMqi0hK9OcC61Q1J9BEEakjIvV8z4H+wOoItmdwpfkbb3TNN99+O7xlrBsFY6q2EhO9iMwCPgNOEZEcEbnWmzScYtU2InK8iMz1Xh4HLBaRFcBS4F1VfS96oVddkydDly4wapTrFiEU60bBGCNaAW+Cmp6erllZWfEOo0LbtAnS0lwfO5984ppuBpKSEvhg0KYNbN5cnhEaY2JJRLKDXatkXSBUUieeCNOnw9KlMGZM8PmsGwVjjCX6SuzXv3Z96kyZEvwK3GDdJVg3ClhuzRQAABKmSURBVMZUHZboK7lJk+D00+Hqq+Hrr4+ePmGC6zbBn3WjYEzVYom+kqtVC1591fWZc9llrp29v4wMmDbN1cmLuMdp08rWjYK13jGmcrJEnwDatoUXX4TsbPjDH46enpHhTrwWFrrHsiZ5a71jTOVkiT5BDB3qest88kl3BW202U1QjKm8LNEnkIkToUcPuO462BCs96EystY7xlRelugTSFKSq69PSnL19T/9FL11W+sdYyovS/QJpnVrd5er5cvh1lujt15rvWNM5WWJPgFdcAHceSc8+yzMCtW3aClEs/WOMSa2LNEnqAcegJ49XcuY9eujs85otN4Ba6ZpTKxZok9QSUkwezYkJ8NvfhP4JuPxUBGbaarCjh3wfZW74aWpKqxTswT33nswcCBce63ryz4chYXuHrXbtgUefvoJunWDXr3gjDPcvWzDFa9O1g4edC2ENm1yw9dfH/l83z43X7Nm0KEDdOx45GODBuUXmzHREKpTM0v0VcD48fDgg+4k7ZAhgZP3d98dfp6bG/gOVk2buvvgisCqVXDokKt+6dzZJf2zznKPzZsHj6VaNVeCLk7EHWAikZ8fOJFv2uSS/KFDh+etVctdaHbiiW5o185NX7MGVq+Gr746nPzBve/iyb99e6hXL7KYTem9/z789a/uc+vRww0nn+y+Q1WZJfoqrqAAzj0X/v3vwNMbNHCJLNTQvLlLjj75+bBkiesiefFi+Pzzw9VDJ510ZOL3/xFGUqL/8Ue3rG+YOxc+/NBtt1q1ow8UjRsfTuL+Cf3EE917qhai4rKw0B0c1qw5nPzXrHEHAP9mq23aHJn8O3SA004L3m20KbvCQtfK65573Oe3d6/7HgI0bAjdu7uk3727+8fZqFF84401S/SGvDx45hmoU+fIBN6ihRsXqYMH4csvDyf+xYsP13k3a3Y48efnw0MPwYEDh5etXdu1ELrgApfAN28+MqH7xu3cGTqGpCR3962rrnIJvX79yN9XcYcOwTffHJn816yBdevgl1/cPCkp8MgjcOmlVsqMlh9+gCuugHnz3OMzz7jzT+vWuULGkiXucfXqw/8YTznlcPLv0cMdgGvUiO/7KE8RJXoRmQ4MBnaoakdv3L3Ab4E8b7Zxqjo3wLIDgMeB6sDzqjoxnIAt0Vd+qq61jy/xf/KJS5Dg/hmIuJLxMce4kveePYdLZz61a7sSc5s2Lnn6nrdp4y4I++67o7cbrxuqFBTAxo3uYDdxIqxc6Q5ujz0G6QF/eiZc2dnuoLltGzz+OFx/ffADaH4+ZGW5pO8bduxw02rXhq5dDyf+7t2hZcvYvY/yFmmi7w3sA14uluj3qeqjIZarDvwXOA/IAb4ARqjqVyUFbIk+MX333eHS/iefwNatcMIJRydx3+vGjYP/oMuzrj9Shw65m8LcdZdLMiNHunMkiZRUYkEVXngBbr7Z/St8/XVXJVPadWzZcmSpf9myw/++mjWDJk1c9WX9+u7RN5T0Ojk5+u85EhFX3YhICvBOKRP9GcC9qnq+9/pPAKr6UEnbs0RvSlIZbpG4d69L8I895qoM7rwT/vjHo68wNkc7cABuuglmzID+/V3z2yZNorPun3+GFStc0l+1CnbvPnLYswd27XL/0kKpWfNw0m/ZEs4/3zV2OPXU+FTZlVeivwrYC2QBd6jqrmLLXAoMUNXrvNdXAt1V9eYg2xgNjAZo3bp11y0l3fXaVGm+9vj+1wfUrl0xr9b95ht3u8d//MMlhIkT4fLLQ58MjoYdO+CDD1xVWbt25XfeIto2bXJ3T1uxAu6+2w3Vq8c2BlV3sNmz5+iDQKDn69a5bkfAteYaPNgl/d69j2zEUJ5CJXpUtcQBSAFW+70+DlfvXg2YAEwPsMxvcPXyvtdXAk+Es72uXbuqMSWZOVO1TRtVEfc4c2a8Iwpt0SLVrl1VQfX001X/85/orr+wUPWrr1QnTlQ980y3X1zKOjw0buy2PWyY6p/+pPrcc6offqj6zTeqBQXRjacs3npLtX591YYNVd99N97RlM7WrarPPqs6eLBqcrLb33Xrql5yier06arbt5fv9oEsDZJTy1SiD2eaVd0Yc7TCQnjlFRg3zp1cHDYMHn7YVTmVRUEBfPopvPWWG3zdU6elwYUXupZM1aq56wqKD1u2HFk9UaOGqxLzlf6LD+X5b6CgwJXcH3rInTB9/XUXS2W1fz8sXAhvvw3vvOPOT4m4cwy+0n5qanSreMqj6qaFquZ6z2/DVckML7ZMDdzJ2HOA73AnYy9X1TUlbc8SvUl0P/7ommBOmuSS/x13wNix4V2AlZ/vLhp68014913X9DApCfr1czegGTzYneQuSUEB5OQcmfx9F5t9/bVbr7/UVHeV9cCBcOaZbpvRsGMHjBgBH33kquMef7zineiMhKqrhvIl/aVL3fhWrdxnNXiw++yOOSay7URUdQPMAnKBg7jWM9cCrwCrgJXAW0ALb97jgbl+yw7CJftNwPiStuUbrOrGVBXffquakeH+5jdvrvrCC4GrULZuVf3b31QHDFCtWdPN36iR6pVXqv7jH6p79kQ/tl27VJctU339ddUHHlDt21e1Rg237Xr1VC++WHXaNBdbWX36qWrLlq6qY8aMqIVeoeXmus/54otV69Rx+/OYY1SHDHFVPwcPlm29RFp1E2tWojdVzZIlcNtt8NlnrkuJyZPd1Z6+KpnsbDffSSe5UvuFF7pSdawvANq7112NPG+eG3Jy3PiOHQ+X9nv2LPnKYFV328vbb3f3UHjjDfe+q5qff4aPP3Yl/bffduO++aZsVToRn4yN9WAlehNLFeWkbmGh6qxZqq1bHz55KuJOrE6c6E60FhbGJ7ZACgtVV61SnTRJtV8/1aSkwycghw5VfeYZ1S1bjl4uP191xAg375Ah7p+DcfszkhO2WInemMAqYjPNAwdc+/HkZFd/26xZfOIorfx8V8/uK+377ifcvv3h0n7Tpq4+ft06d8+EMWPKv5lpVWF93RgTRGW48KoyUoW1a1032fPmwaJFh69GbdrU3fnsnHPiG2OisURvTBAVuSuFRLJvn2tuuHIljBrlWpyY6AqV6BO4LzdjSta6deASfevWsY8lkdWt69qODxkS70iqJqsdM1XahAlH9z1Tu7Ybb0yisERvqrSMDHfitU0bV13Tpk3F7C/HmEhYojdVXkaGO/FaWOgey5rkMzPdyd1q1dxjPG94bow/q6M3JgqKN9PcssW9Bvt3YOLPSvTGRMH48Ue2xQf3evz4+MRjjD9L9MZEge/ioHDHGxNLluiNiYJgzTGtmaapCCzRGxMF1kzTVGSW6I2JAmumaSoya3VjTJRkZFhiNxWTleiNMSbBlZjoRWS6iOwQkdV+4yaJyDoRWSkic0SkQZBlN4vIKhFZLiLWS5kxxsRBOCX6F4EBxcYtADqqairuVoF/CrH82araOVivasYYY8pXiYleVRcBPxQb976q+u4f/zlgnY4aEyXWlYKJtmjU0V8DzAsyTYH3RSRbREaHWomIjBaRLBHJysvLi0JYxlQ+vq4Utmxx/eT7ulKwZG8iEVGiF5HxQAEQ7GvYU1XTgIHATSLSO9i6VHWaqqaranrTpk0jCcuYSsu6UjDlocyJXkRGAYOBDA1ymypV3eY97gDmAN3Kuj1jqgLrSsGUhzIlehEZAIwBLlTV/UHmqSMi9XzPgf7A6kDzGmMc60rBlIdwmlfOAj4DThGRHBG5FngSqAcs8JpOPuPNe7yIzPUWPQ5YLCIrgKXAu6r6Xrm8C2MShHWlYMpDiVfGquqIAKNfCDLvNmCQ9/xroFNE0RlTxfiurB0/3lXXtG7tkrxdcWsiYVfGGlPBVLQ7Xllzz8rP+roxJgFF645XduesxCBBGszEVXp6umZlWY8JxpRVSopLysW1aeP+JcR6Pab8iUh2sB4IrOrGmAQUrWaa0WzuaVVA8WOJ3pgEFK1mmtFaj13xG1+W6I1JQNFqphmt9dgVv/Flid6YBBStO15Faz12xW982clYY0y5s5O65c9Oxhpj4squ+I0vS/TGmHJnN0+PL7tgyhgTE3bz9PixEr0xxiQ4S/TGGJPgLNEbYyoNu7q2bKyO3hhTKVgHa2VnJXpjTKVgV9eWXViJXkSmi8gOEVntN66RiCwQkQ3eY8Mgy47y5tng3WfWGGNKza6uLbtwS/QvAgOKjRsLfKiqJwMfeq+PICKNgHuA7rgbg98T7IBgjDGh2P10yy6sRK+qi4Afio0eCrzkPX8JuCjAoucDC1T1B1XdBSzg6AOGMcaUyK6uLbtI6uiPU9VcAO+xWYB5WgJb/V7neOOOIiKjRSRLRLLy8vIiCMsYk4js6tqyK+9WNxJgXMBe1FR1GjANXKdm5RmUMaZysqtryyaSEv12EWkB4D3uCDBPDnCC3+tWwLYItmmMMaaUIkn0bwG+VjSjgDcDzDMf6C8iDb2TsP29ccYYEzdV7cKrcJtXzgI+A04RkRwRuRaYCJwnIhuA87zXiEi6iDwPoKo/APcDX3jDfd44Y4yJi2je1rCyHDDsxiPGmColWjdBKX6lLrhWQPE6QWw3HjHGGE+0LryK5pW65f3PwBK9MaZKidaFV9E6YESzKikYS/TGmColWhdeReuAEYs+fCzRG2OqlGhdeBWtA0Ys+vCxRG+MqXIyMtyJ18JC91iWk6fROmDEog8fS/TGGFNG0ThgxKIPH0v0xhgTR7How8fuMGWMMXFW3n34WIneGGMSnCV6Y4xJcJbojTEmwVmiN8aYBGeJ3hhjElyF7L1SRPKAAP3LVThNgO/jHUQpVLZ4wWKOlcoWc2WLF8o/5jaq2jTQhAqZ6CsLEckK1i1oRVTZ4gWLOVYqW8yVLV6Ib8xWdWOMMQnOEr0xxiQ4S/SRmRbvAEqpssULFnOsVLaYK1u8EMeYrY7eGGMSnJXojTEmwVmiN8aYBGeJPgQROUFEForIWhFZIyK3BJinr4jsEZHl3nB3PGItFtNmEVnlxZMVYLqIyFQR2SgiK0UkLR5x+sVzit/+Wy4ie0Xk1mLzxH0/i8h0EdkhIqv9xjUSkQUissF7bBhk2VHePBtEZFScY54kIuu8z36OiDQIsmzI71EM471XRL7z++wHBVl2gIis977XY2MRb4iYX/WLd7OILA+ybGz2saraEGQAWgBp3vN6wH+B9sXm6Qu8E+9Yi8W0GWgSYvogYB4gQA9gSbxj9outOvA/3MUfFWo/A72BNGC137hHgLHe87HAwwGWawR87T029J43jGPM/YEa3vOHA8UczvcohvHeC/whjO/NJqAdUBNYUfy3GsuYi03/K3B3PPexlehDUNVcVV3mPc8H1gIt4xtVVAwFXlbnc6CBiLSId1Cec4BNqlrhroxW1UXAD8VGDwVe8p6/BFwUYNHzgQWq+oOq7gIWAAPKLVA/gWJW1fdVtcB7+TnQKhaxhCPIPg5HN2Cjqn6tqr8As3GfTbkLFbOICHAZMCsWsQRjiT5MIpICdAGWBJh8hoisEJF5ItIhpoEFpsD7IpItIqMDTG8JbPV7nUPFOYANJ/iPoqLtZ4DjVDUXXMEAaBZgnoq8v6/B/bsLpKTvUSzd7FU1TQ9SPVZR9/FZwHZV3RBkekz2sSX6MIhIXeAN4FZV3Vts8jJcNUMn4AngX7GOL4CeqpoGDARuEpHexaZLgGXi3s5WRGoCFwL/CDC5Iu7ncFXU/T0eKAAyg8xS0vcoVp4GTgQ6A7m4qpDiKuQ+BkYQujQfk31sib4EIpKES/KZqvrP4tNVda+q7vOezwWSRKRJjMMsHtM273EHMAf3t9ZfDnCC3+tWwLbYRBfSQGCZqm4vPqEi7mfPdl+1l/e4I8A8FW5/eyeEBwMZ6lUWFxfG9ygmVHW7qh5S1ULguSBxVMR9XAO4BHg12Dyx2seW6EPw6tdeANaq6uQg8zT35kNEuuH26c7YRXlUPHVEpJ7vOe7E2+pis70FjPRa3/QA9viqH+IsaOmnou1nP28BvlY0o4A3A8wzH+gvIg29aof+3ri4EJEBwBjgQlXdH2SecL5HMVHs/NHFQeL4AjhZRNp6/wyH4z6beDoXWKeqOYEmxnQfx+KsdGUdgF64v38rgeXeMAi4AbjBm+dmYA3uLP/nwJlxjrmdF8sKL67x3nj/mAV4CtdKYRWQXgH2dW1c4q7vN65C7WfcQSgXOIgrQV4LNAY+BDZ4j428edOB5/2WvQbY6A1Xxznmjbj6bN93+hlv3uOBuaG+R3GK9xXve7oSl7xbFI/Xez0I1zJuU6ziDRazN/5F3/fXb9647GPrAsEYYxKcVd0YY0yCs0RvjDEJzhK9McYkOEv0xhiT4CzRG2NMgrNEb4wxCc4SvTHGJLj/D4O38JRZICDjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display curves of loss and accuracy during training and save results \n",
    "plot_save_acc_loss(results_dir, history.history, Model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load_tf_custom_loss ( dir, name, custom_loss):\n",
    "        from tensorflow.keras.models import load_model\n",
    "#        from keras.models import load_model\n",
    "# Load model from tf      \n",
    "        print ( str(custom_loss))\n",
    "        print ( custom_loss )      \n",
    "       \tmodel = load_model(dir+name+'.h5', custom_objects = {\"str(custom_loss)\": custom_loss})\n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score_loss\n",
      "roc_auc_score_loss\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:roc_auc_score_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-18ee4792de37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mModel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ModelK15_1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"roc_auc_score_loss\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_load_tf_custom_loss\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mmodel_bin_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#    model = load_model(model_bin_dir+Model_name+'.h5', custom_objects = {\"roc_auc_score_loss\": roc_auc_score_loss})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_bin_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Best_weights\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mModel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-0ed00e527d79>\u001b[0m in \u001b[0;36mmodel_load_tf_custom_loss\u001b[0;34m(dir, name, custom_loss)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mcustom_loss\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"str(custom_loss)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Compile model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       model.compile(**saving_utils.compile_args_from_training_config(\n\u001b[0;32m--> 184\u001b[0;31m           training_config, custom_objects))\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# Prepare list of loss functions, same size of model outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     self.loss_functions = training_utils.prepare_loss_functions(\n\u001b[0;32m--> 336\u001b[0;31m         self.loss, self.output_names)\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mtarget_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_target_tensor_for_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mprepare_loss_functions\u001b[0;34m(loss, output_names)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       \u001b[0mloss_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m     \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       \u001b[0mloss_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m     \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mget_loss_function\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   \u001b[0;31m# Wrap loss function with signature `(y_true, y_pred, **kwargs)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m   \u001b[0;31m# in `LossFunctionWrapper` class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m   \u001b[0;31m# For losses which are given as strings/functions in the compile API,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m   1181\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m       printable_module_name='loss function')\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktf2/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Classes passed by name are instantiated with no args, functions are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# returned as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:roc_auc_score_loss"
     ]
    }
   ],
   "source": [
    "# Load Model \n",
    "# Load weights \n",
    "# Import with this compatibility to solve the problem \n",
    "# module 'tensorflow' has no attribute 'placeholder'`.\n",
    "\n",
    " \n",
    "#model = build_model()\n",
    "#model.load_weights('my_weights.model')\n",
    "from tensorflow.keras.models import load_model\n",
    "TRAIN = False\n",
    "if not TRAIN :\n",
    "    Model_name = \"ModelK15_1\"\n",
    "    loss = \"roc_auc_score_loss\"\n",
    "    model = model_load_tf_custom_loss ( model_bin_dir, Model_name, loss )\n",
    "#    model = load_model(model_bin_dir+Model_name+'.h5', custom_objects = {\"roc_auc_score_loss\": roc_auc_score_loss})\n",
    "    model.load_weights(model_bin_dir+\"Best_weights\"+Model_name+\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors from images\n",
    "# Load Images \n",
    "\n",
    "# This step is very time consuming !!!!!!!\n",
    "\n",
    "test_image_tensor  = load_images_tf(dftest,height_imag,width_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label tensor\n",
    "test_label_tensor = create_label_tensor(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AUC Loss:  12.7444077\n",
      " AUC Loss:  12.7444077\n",
      " AUC Loss:  17.264286\n",
      " AUC Loss:  17.264286\n",
      " AUC Loss:  21.2008362\n",
      " AUC Loss:  21.2008362\n",
      " AUC Loss:  15.9233551\n",
      " AUC Loss:  15.9233551\n",
      " AUC Loss:  12.4778328\n",
      " AUC Loss:  12.4778328\n",
      " AUC Loss:  3.33313513\n",
      " AUC Loss:  3.33313513\n",
      "700/1 - 1s - loss: 9.0881 - acc: 0.6914 - roc_auc_score_loss: 13.8240\n"
     ]
    }
   ],
   "source": [
    "#  ROC /AUC\n",
    "# Model evaluate \n",
    "# Returns the loss value & metrics values for the model in test mode.\n",
    "scores = model.evaluate(test_image_tensor, test_label_tensor, batch_size = 128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.843085689544678, 0.69142854, 13.823976]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names\n",
    "# Loss + Accuracy + roc auc score \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = model.predict(test_image_tensor).ravel()   # y_pred_probabilities\n",
    "y_test = dftest.bm.astype('category').cat.codes           # Ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68919116 0.56542885 0.556891   0.4414358  0.36796543]\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "dtype: int8\n"
     ]
    }
   ],
   "source": [
    "print ( y_pred_keras[0:5])\n",
    "print ( y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8373202614379085\n"
     ]
    }
   ],
   "source": [
    "# Compute AUC score from sklearn \n",
    "import sklearn \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# y_test true labels \n",
    "# y_pred_keras predictions \n",
    "print ( sklearn.metrics.roc_auc_score(y_test, y_pred_keras)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()  # Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocess_Fit4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ktf2",
   "language": "python",
   "name": "ktf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
